<!DOCTYPE HTML>
<html lang="zh-CN">


<head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="utf-8">
    <meta name="keywords" content="机器学习常见算法总结, ZZU 行码棋">
    <!-- 百度和谷歌统计验证 -->
    <meta name="baidu-site-verification" content="code-L7AVcsbU14">
    <meta name="google-site-verification" content="x4QfrBHn9imI1RhTNCB8RD8Q2Rx6rE_zylSBptBgdZY">
    <!-- <meta name="360-site-verification" content="b7c11a830ef90fd1464ad6206bb7b6e7" /> -->
    <meta name="description" content="机器学习环境搭建
一般使用anaconda搭建python虚拟环境（miniconda占的空间应该小一点，这个也可以）

使用工具库一般有科学计算库numpy，数据处理库pandas，绘图matplotlib等，需要了解相关用法

……

">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <title>机器学习常见算法总结 | 行码棋</title>
    <link rel="icon" type="image/png" href="/medias/logo.png">

    <link rel="stylesheey" type="text/css" href="//at.alicdn.com/t/c/font_3948353_97hiukrvyh.css">
    <!-- fa图标css文件引入 -->
    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/font-awesome.min.css">
    <link rel="stylesheet" type="text/css" href="https://lib.baomitu.com/materialize/1.0.0/css/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="https://lib.baomitu.com/aos/2.3.4/aos.css">
    <link rel="stylesheet" type="text/css" href="https://lib.baomitu.com/animate.css/3.5.1/animate.min.css">
    <link rel="stylesheet" type="text/css" href="https://lib.baomitu.com/lightgallery/1.6.11/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">

    <!-- 调用今日诗词API -->
    <script src="https://lib.baomitu.com/jquery/2.2.0/jquery.min.js"></script>
    <script src="https://sdk.jinrishici.com/v2/browser/jinrishici.js" charset="utf-8"></script>
    <!-- wyqz.top 百度统计-->
    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?7e24aec910e98687980f650c88fc0424";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-5396110595574182" crossorigin="anonymous">
    </script>
            
    <!-- 百度推送 -->
    
        <script>
            (function(){
                var bp = document.createElement('script');
                var curProtocol = window.location.protocol.split(':')[0];
                if (curProtocol === 'https') {
                    bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
                }
                else {
                    bp.src = 'http://push.zhanzhang.baidu.com/push.js';
                }
                var s = document.getElementsByTagName("script")[0];
                s.parentNode.insertBefore(bp, s);
            })();
        </script>
    

    <script>
        (function(){
        var src = "https://jspassport.ssl.qhimg.com/11.0.1.js?d182b3f28525f2db83acfaaf6e696dba";
        document.write('<script src="' + src + '" id="sozz"><\/script>');
        })();
    </script>
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head>

<body>

    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">行码棋</span>
                </a>
            </div>
            <!-- PC端菜单栏文字显示 -->


<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fa fa-navicon"></i></a>
<ul class="right">
    
    <li class="hide-on-med-and-down">
        <a href="/" class="waves-effect waves-light">
            
            <i class="fa fa-home"></i>
            
            <span>首页</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/tags" class="waves-effect waves-light">
            
            <i class="fa fa-tags"></i>
            
            <span>标签</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/categories" class="waves-effect waves-light">
            
            <i class="fa fa-bookmark"></i>
            
            <span>分类</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/archives" class="waves-effect waves-light">
            
            <i class="fa fa-archive"></i>
            
            <span>历程</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/friends" class="waves-effect waves-light">
            
            <i class="fa fa-address-book"></i>
            
            <span>友链</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/about" class="waves-effect waves-light">
            
            <i class="fa fa-user-circle-o"></i>
            
            <span>知悉</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/contact" class="waves-effect waves-light">
            
            <i class="fa fa-comments"></i>
            
            <span>微语</span>
        </a>
    </li>
    
    <li>
        <a href="#searchModal" class="modal-trigger waves-effect waves-light">
            <i id="searchIcon" class="fa fa-search" title="搜索"></i>
        </a>
    </li>
</ul>

<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">行码棋</div>
        <div class="logo-desc">
            
            金牌选手不会从天而降，你必须用热爱、刻苦和投入来浇灌他们。
            
        </div>
    </div>
    <!-- 手机端导航栏 -->
    

    <ul class="menu-list mobile-menu-list">
        
        <li>
            <a href="/" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-home"></i>
                
                首页
            </a>
        </li>
        
        <li>
            <a href="/tags" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-tags"></i>
                
                标签
            </a>
        </li>
        
        <li>
            <a href="/categories" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-bookmark"></i>
                
                分类
            </a>
        </li>
        
        <li>
            <a href="/archives" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-archive"></i>
                
                历程
            </a>
        </li>
        
        <li>
            <a href="/friends" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-address-book"></i>
                
                友链
            </a>
        </li>
        
        <li>
            <a href="/about" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-user-circle-o"></i>
                
                知悉
            </a>
        </li>
        
        <li>
            <a href="/contact" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-comments"></i>
                
                微语
            </a>
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/anda522/anda522.github.io" class="waves-effect waves-light" target="_blank">
                <i class="fa fa-github-square fa-fw"></i>Github Page
            </a>
        </li>
        
    </ul>
</div>

        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/anda522/anda522.github.io" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Github Page" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    
<script src="https://lib.baomitu.com/crypto-js/4.1.1/crypto-js.min.js"></script>
<script>
    (function() {
        let pwd = '';
        if (pwd && pwd.length > 0) {
            if (pwd !== CryptoJS.SHA256(prompt('请输入访问本文章的密码')).toString(CryptoJS.enc.Hex)) {
                alert('密码错误，将返回主页！');
                location.href = '/';
            }
        }
    })();
</script>




<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/24.jpg')">
    <div class="container">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <div class="description center-align post-title">
                        机器学习常见算法总结
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>



<main class="post-container content">

    
    <link rel="stylesheet" href="https://lib.baomitu.com/tocbot/latest/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }
    /* 目录背景白框 */
    .toc-widget {
        padding-left: 20px;
        background-color: white;
        padding: 10px;
        position: fixed;
        border-radius: 10px;
        width: 16%;
        margin-top: 20px;
    }

    .toc-widget .toc-title {
        margin: 35px 0 15px 0;
        padding-left: 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content ol {
        position: relative;
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #toc-content .is-active-link::before {
        background-color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 20px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                        <a href="/tags/学习总结/" target="_blank">
                            <span class="chip bg-color">学习总结</span>
                        </a>
                        
                        <a href="/tags/MachineLearning/" target="_blank">
                            <span class="chip bg-color">MachineLearning</span>
                        </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fa fa-bookmark fa-fw icon-category"></i>
                        
                        <a href="/categories/人工智能/" class="post-category" target="_blank">
                            人工智能
                        </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                <div class="post-date info-break-policy">
                    <i class="fa fa-calendar-minus-o fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2022-12-27
                </div>

                <div class="post-author info-break-policy">
                    <i class="fa fa-user-o fa-fw"></i>作者:&nbsp;&nbsp;
                    
                    行码棋
                    
                </div>

                
                
                <div class="info-break-policy">
                    <i class="fa fa-file-word-o fa-fw"></i>文章字数:&nbsp;&nbsp;
                    11.7k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="fa fa-clock-o fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    47 分
                </div>
                
                
                <!-- 文章访问次数统计 -->
                
                <div id="busuanzi_container_page_pv" class="info-break-policy">
                    <i class="fa fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                    <span id="busuanzi_value_page_pv"></span>
                </div>
                
            </div>
        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="机器学习环境搭建"><a href="#机器学习环境搭建" class="headerlink" title="机器学习环境搭建"></a>机器学习环境搭建</h1><ul>
<li><p>一般使用anaconda搭建python虚拟环境（miniconda占的空间应该小一点，这个也可以）</p>
</li>
<li><p>使用工具库一般有科学计算库numpy，数据处理库pandas，绘图matplotlib等，需要了解相关用法</p>
</li>
<li><p>……</p>
</li>
</ul>
<h1 id="线性回归-Linear-Regression"><a href="#线性回归-Linear-Regression" class="headerlink" title="线性回归 Linear Regression"></a>线性回归 Linear Regression</h1><h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1 概述"></a>1 概述</h2><p>线性回归类似高中的<strong>线性规划</strong>题目。线性回归要做的是就是找到一个数学公式能相对较完美地把所有自变量组合（加减乘除）起来，得到的结果和目标接近。</p>
<p>线性回归分为一元线性回归和多元线性回归。</p>
<h2 id="2-一元线性回归"><a href="#2-一元线性回归" class="headerlink" title="2 一元线性回归"></a>2 一元线性回归</h2><h3 id="2-1-构造回归方程"><a href="#2-1-构造回归方程" class="headerlink" title="2.1 构造回归方程"></a>2.1 构造回归方程</h3><p>有n组数据，自变量（特征值） $x(x_1,x_2,…,x_n)$ 与因变量（目标值） $y(y_1,y_2,…,y_n)$ ，我们需要找到一个线性关系，使他们之间尽可能满足： $f(x) =ax+b$ ，这个就是构建的一元线性方程。</p>
<p><img src="808139430/1.jpg" alt="一元线性回归"></p>
<p>线性回归的目标就是让 $f(X)$ 与 $y$ 之间的差距最小，也就是权重$a$和偏置$b$取什么值的时候$f(X)$和$y$最接近。</p>
<h3 id="2-2-构造损失函数"><a href="#2-2-构造损失函数" class="headerlink" title="2.2 构造损失函数"></a>2.2 构造损失函数</h3><p>损失函数是来度量模型预测值与真实值不一样的程度的，或者说度量预测错误的程度，损失函数值越小，模型就越好。</p>
<p>在回归问题中，误差平方和是回归任务中最常用的性能度量。这里就可以令损失函数$L(a,b)$等于误差平方和（均方误差）。</p>
<p>则损失函数为: $L(a, b) = \sum \limits_{i = 1}^{n}(f(x_i) - y_i)^2$</p>
<h3 id="2-3-确定参数"><a href="#2-3-确定参数" class="headerlink" title="2.3 确定参数"></a>2.3 确定参数</h3><p>我们需要通过最小的损失函数得到最佳的参数 $a$ 和 $b$ 。一般使用<strong>最小二乘法</strong>。<br>$$<br>a = \frac{\sum \limits_{i=1}^{n}x_iy_i - n \overline x \overline y}{\sum \limits_{i=1}^{n}x_i^2 - n \overline x ^ 2}<br>\\<br>b = \overline y - a \overline x<br>$$</p>
<h2 id="3-多元线性回归"><a href="#3-多元线性回归" class="headerlink" title="3 多元线性回归"></a>3 多元线性回归</h2><p>多元线性回归类似一元</p>
<p>回归方程： $y = a_1 x_1 + a_2 x_2 + a_3 x_3 + … + a_n x_n + b$</p>
<p>对所有的数据统一用矩阵形式表示：<br>$$<br>y^{(i)} = \theta ^ T x ^ {(i)} + \varepsilon^{(i)} \ (1)<br>$$</p>
<blockquote>
<p>$y^{(i)}$表示第<code>i</code>个样本的真实值</p>
<p>$\varepsilon$ 误差代表真实值和预测值之间的差异</p>
<p>误差 $\varepsilon ^{(i)}$ 是独立并具有相同的分布，服从均值为 0 方差为 $\theta ^ 2$ 的高斯分布</p>
</blockquote>
<p>损失函数<br>$$<br>L(a_1, a_2, …, a_n, b) = \sum_{i = 1}^{n}(f(x_i) - y_i)^2<br>$$</p>
<p>高斯分布的概率函数：<br>$$<br>p(x) = \frac{1}{\sqrt {2 \pi} \sigma} \exp{(-\frac{x^2}{2 \sigma ^ 2})} \  (2)<br>$$<br>将<code>(1)</code>带入<code>(2)</code>得到<strong>预测值成为真实值的概率</strong>函数：<br>$$<br>p(y ^ {(i)} | x ^ {(i)}; \theta) = \frac{1}{\sqrt {2 \pi} \sigma} \exp{(-\frac{(y^{(i)} - \theta ^ T x ^ {(i)})^2}{2 \sigma ^ 2})}<br>$$<br>似然函数：（什么样的参数计算出来的误差最小，即与实际值最接近）<br>$$<br>L(\theta) = \prod \limits_{i = 1}^{m} p(y ^ {(i)} | x ^ {(i)}; \theta) = \prod \limits_{i=1}^{m}\frac{1}{\sqrt {2 \pi} \sigma} \exp{(-\frac{(y^{(i)} - \theta ^ T x ^ {(i)})^2}{2 \sigma ^ 2})}<br>$$<br>对数似然法：（将乘法转化为加法），之后需要用极大似然估计方法求解<br>$$<br>ln L(\theta) = ln \prod \limits_{i=1}^{m}\frac{1}{\sqrt {2 \pi} \sigma} \exp{(-\frac{(y^{(i)} - \theta ^ T x ^ {(i)})^2}{2 \sigma ^ 2})}<br>$$<br>展开化简：<br>$$<br>ln L(\theta) = \sum \limits_{i = 1}^{m}ln \frac{1}{\sqrt {2 \pi} \sigma} \exp{(-\frac{(y^{(i)} - \theta ^ T x ^ {(i)})^2}{2 \sigma ^ 2})}<br>\\<br>= mln \frac{1}{\sqrt {2 \pi} \sigma} - \frac{1}{\sigma^2} \frac{1}{2} \sum \limits _{i = 1}^{m} (y^{(i)} - \theta ^ T x ^ {(i)})^2<br>$$</p>
<p>目标：让似然函数越大越好（极大似然估计），即让$J(\theta)$越小越好（可以使用<strong>最小二乘法</strong>求解）<br>$$<br>J(\theta) = \frac{1}{2} \sum \limits _{i = 1}^{m} (y^{(i)} - \theta ^ T x ^ {(i)})^2<br>$$</p>
<blockquote>
<p>其实由损失函数也可以得到同样的式子：</p>
<p>对于$y = \theta x + b$，$\theta$ 将 $b$ 也吸入进入得到 $\hat \theta = (\theta, b)$ ，$X$代表所有的样本数据，最后一个元素置1，最后要和 $\hat\theta$ 相乘，最后求偏导也是一样的结果。<br>$$<br>L = \sum \limits_{i = 1}^n ( y_i - f(x_i)) ^ 2 = (y - X \hat\theta)^T(y - X \hat\theta) \\<br>X =<br>\begin{pmatrix}<br>x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1d} &amp; 1 \\<br>x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1d} &amp; 1 \\<br>\vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots \\<br>x_{m1} &amp; x_{m2} &amp; \cdots &amp; x_{md} &amp; 1<br>\end{pmatrix}<br>=<br>\begin{pmatrix}<br>x_1^T &amp; 1 \\<br>x_2^T &amp; 1 \\<br>\vdots &amp; \vdots \\<br>x_m^T &amp; 1<br>\end{pmatrix}<br>$$</p>
</blockquote>
<p><img src="808139430/image-20221227173603912.png" alt="最小二乘法分析"></p>
<blockquote>
<p>矩阵求导参考：</p>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/263777564" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/263777564</a> （先导篇）</li>
<li><a href="https://zhuanlan.zhihu.com/p/273729929" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/273729929</a> （公式篇）</li>
</ul>
</blockquote>
<p><img src="808139430/image-20221227173755095.png" alt="评估方法"></p>
<h2 id="4-梯度下降"><a href="#4-梯度下降" class="headerlink" title="4 梯度下降"></a>4 梯度下降</h2><p>梯度下降法（gradient descent）是一种常用的一阶（first-order）优化方法。主要解决求最小值问题，其基本思想在于不断地逼近最优点，每一步的优化方向就是梯度的方向。</p>
<h3 id="4-1-梯度下降方法"><a href="#4-1-梯度下降方法" class="headerlink" title="4.1 梯度下降方法"></a>4.1 梯度下降方法</h3><ul>
<li>批量梯度下降</li>
</ul>
<p>容易得到最优解，但是由于每次考虑<strong>所有样本</strong>，速度很慢。</p>
<ul>
<li>随机梯度下降</li>
</ul>
<p>每次找一个样本，迭代速度很快，但不一定每次都朝着收敛的方向。</p>
<ul>
<li>小批量梯度下降</li>
</ul>
<p>每次更新一小部分数据来算，因为在整个训练集上算梯度资源消耗太大，我们可以随机采取$b$个样本$i_1, i_2, \cdots, i_b$来近似损失，$e$是损失函数，$b$是批量大小。<br>$$<br>\frac{1}{b} \sum \limits_{i \in I_b} \mathcal{e}(\mathbf{x_i}, y_i, \mathbf{w})<br>$$</p>
<h3 id="4-2-其他参数"><a href="#4-2-其他参数" class="headerlink" title="4.2 其他参数"></a>4.2 其他参数</h3><ul>
<li>学习率：更新的步长</li>
</ul>
<p><img src="808139430/image-20221228161134519.png" alt="学习率的影响"></p>
<ul>
<li>批处理数量</li>
</ul>
<p>一般<code>batch_size</code>选择32，64，128等，有时候会考虑内存和效率。</p>
<h1 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h1><p>逻辑回归是一个经典的二分类算法。</p>
<h2 id="1-sigmoid函数"><a href="#1-sigmoid函数" class="headerlink" title="1 sigmoid函数"></a>1 sigmoid函数</h2><p>$$<br>g(z) = \frac{1}{1 + e ^ {-z}}, z \in R<br>$$</p>
<p><img src="808139430/image-20221228161724190.png" alt="sigmoid函数图像"></p>
<blockquote>
<p>将任意的输入映射到了$[0, 1]$区间中，在线性回归中可以得到一个预测值，再将该值映射到sigmoid函数中，这样就可以完成由值到概率的转换，这就是分类任务。</p>
</blockquote>
<h2 id="2-逻辑回归求解"><a href="#2-逻辑回归求解" class="headerlink" title="2 逻辑回归求解"></a>2 逻辑回归求解</h2><p>预测函数：<br>$$<br>h_{\theta}(x) = g(\theta ^ T x) = \frac{1}{1 + e ^ {-\theta^T x}} \\<br>其中 \theta_0 + \theta_1 x_1 + … + \theta_n x_n = \sum \limits_{i = 1}^n \theta_i x_i = \theta ^ T x<br>$$<br>分类任务：<br>$$<br>\begin{cases}<br>P(y = 1|x; \theta) = h_\theta(x) \\<br>P(y = 0|x; \theta) = 1 - h_\theta(x)<br>\end{cases}<br>\Rightarrow<br>P(y | x; \theta) = (h_\theta(x)) ^ y (1 - h_\theta(x)) ^ {1 - y}<br>$$<br>对于二分类任务（0， 1），整合后，<code>y</code>取0只保留$(1 - h_\theta(x)) ^ {1 - y}$ ，<code>y</code>取1只保留 $(h_\theta(x)) ^ y$ 。</p>
<p>似然函数：<br>$$<br>L(\theta) = \prod \limits_{i = 1}^m P(y_i | x_i; \theta) = \prod \limits_{i = 1}^m (h_\theta(x_i)) ^ y_i (1 - h_\theta(x_i)) ^ {1 - y_i}<br>$$<br>对数似然法，即求$l(\theta)$ 的最大值：<br>$$<br>l(\theta) = logL(\theta) = \sum \limits_{i = 1} ^m (y_i log h_\theta(x_i) + (1 - y_i) log (1 - h_\theta(x_i)))<br>$$<br>将上述函数转化为求最小值，同时系数乘上一个常数，即求$J(\theta) = -\frac{1}{m}l(\theta)$ 的最小值，转化为梯度下降问题：<br>$$<br>J(\theta) = -\frac{1}{m}l(\theta)<br>$$<br><img src="808139430/image-20221228164952743.png" alt="求导过程"></p>
<p>上述过程即求出了偏导的方向，有了更新方向就可以进行参数更新： $\alpha$代表学习率<br>$$<br>\theta_j = \theta_j - \alpha \frac{1}{m} \sum \limits_{i = 1} ^ m (h_\theta(x_i) - y_i)x_i^j<br>$$</p>
<blockquote>
<p>减法是代表用的梯度下降，整体除以<code>m</code>是考虑了所有的m个样本。</p>
</blockquote>
<p>多分类问题：</p>
<p><img src="808139430/image-20221228171310763.png" alt="多分类"></p>
<blockquote>
<p>Softmax回归是逻辑回归的一般化，相关对比参考 <a href="https://zhuanlan.zhihu.com/p/98061179" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/98061179</a></p>
</blockquote>
<h1 id="模型评估标准"><a href="#模型评估标准" class="headerlink" title="模型评估标准"></a>模型评估标准</h1><h2 id="1-回归模型评估"><a href="#1-回归模型评估" class="headerlink" title="1 回归模型评估"></a>1 回归模型评估</h2><h3 id="1-1-平均绝对误差（Mean-Absolute-Error，MAE）"><a href="#1-1-平均绝对误差（Mean-Absolute-Error，MAE）" class="headerlink" title="1.1 平均绝对误差（Mean Absolute Error，MAE）"></a>1.1 平均绝对误差（Mean Absolute Error，MAE）</h3><p>平均绝对误差就是指预测值与真实值之间平均相差多大<br>$$<br>MAE = \frac{1}{m}\sum \limits _{i = 1}^m \lvert f_i - y_i \rvert<br>$$</p>
<h3 id="1-2-均方误差（Mean-Squared-Error，MSE）"><a href="#1-2-均方误差（Mean-Squared-Error，MSE）" class="headerlink" title="1.2 均方误差（Mean Squared Error，MSE）"></a>1.2 均方误差（Mean Squared Error，MSE）</h3><p>观测值与真值偏差的平方和与观测次数的比值<br>$$<br>MSE = \frac{1}{m} \sum \limits_{i = 1}^m(f_i - y_i)^2<br>$$<br>这也是线性回归中最常用的损失函数，线性回归过程中尽量让该损失函数最小。那么模型之间的对比也可以用它来比较。</p>
<p>MSE可以评价数据的变化程度，MSE的值越小，说明预测模型描述实验数据具有更好的精确度。</p>
<h3 id="1-3-R-square（决定系数）"><a href="#1-3-R-square（决定系数）" class="headerlink" title="1.3 R-square（决定系数）"></a>1.3 R-square（决定系数）</h3><p>$$<br>R^2 = 1 - \frac{\sum(Y_{actual} - Y_{predict})^2}{\sum(Y_{actual} - Y_{mean})^2}<br>$$</p>
<h3 id="1-4-Adjusted-R-Square（校正决定系数）"><a href="#1-4-Adjusted-R-Square（校正决定系数）" class="headerlink" title="1.4 Adjusted R-Square（校正决定系数）"></a>1.4 Adjusted R-Square（校正决定系数）</h3><p>$$<br>R^2_{adjusted} = 1 - \frac{(1 - R^2)(n - 1)}{n - p - 1}<br>$$</p>
<p>n为样本数量，p为特征数量</p>
<p>消除了样本数量和特征数量的影响</p>
<h3 id="1-5-交叉验证"><a href="#1-5-交叉验证" class="headerlink" title="1.5 交叉验证"></a>1.5 交叉验证</h3><p>我们有一个总的数据集，将总数据集切分，例如，将数据分为训练集（80%）和测试集（20%），训练集用来训练model，测试集用来最终的测试。</p>
<p>训练集还再平均进行切分为3份（标号为1、2、3）。</p>
<blockquote>
<p>测试集和训练集的比例自己定。</p>
</blockquote>
<p>交叉验证就是在训练集中，采用2份数据来训练，用另一份数据来验证训练出的模型的参数，进行3次。</p>
<p>即：1 + 2来训练，3验证；2 + 3来训练，1来验证；1 + 3来训练，2来验证。</p>
<p>为了让模型的评估效果比较好，最后将3次的参数取平均值。</p>
<blockquote>
<p>无论分类还是回归模型，都可以利用交叉验证，进行模型评估</p>
<p>sklearn模块中有交叉验证函数，例如<code>sklearn.cross_validation</code> 中的 <code>train_testsplit</code> 函数</p>
</blockquote>
<p>交叉验证主要是为了防止某一部分数据比较简单，导致模型的效果比较高。</p>
<h2 id="2-分类模型评估"><a href="#2-分类模型评估" class="headerlink" title="2 分类模型评估"></a>2 分类模型评估</h2><h3 id="2-1-准确率、精确率、召回率、f1-score"><a href="#2-1-准确率、精确率、召回率、f1-score" class="headerlink" title="2.1 准确率、精确率、召回率、f1_score"></a>2.1 准确率、精确率、召回率、f1_score</h3><ul>
<li><p>准确率（Accuracy）的定义是：对于给定的测试集，分类模型正确分类的样本数与总样本数之比；</p>
</li>
<li><p>精确率（Precision）的定义是：对于给定测试集的某一个类别，分类模型预测正确的比例，或者说：分类模型预测的正样本中有多少是真正的正样本；</p>
</li>
<li><p>召回率（Recall）的定义为：对于给定测试集的某一个类别，样本中的正类有多少被分类模型预测正确；</p>
<blockquote>
<p>假设有1000个人，其中990个人正常，有10个人患有癌症，模型旨在预测哪些人是患有癌症的。</p>
<p>如果模型预测1000个人中都是正常的，没有癌症患者，那么可以说模型的精度是$\frac{990}{1000}=0.99$。虽然精度很高，但是都是正样本，没有负样本，模型是无用的，因为一个患者都没有找到。因此无法用精度来评估模型，而是使用recall召回率来评估。</p>
</blockquote>
</li>
<li><p>F1_score，在理想情况下，我们希望模型的精确率越高越好，同时召回率也越高越高，但是，现实情况往往事与愿违，在现实情况下，精确率和召回率像是坐在跷跷板上一样，往往出现一个值升高，另一个值降低，那么，有没有一个指标来综合考虑精确率和召回率了，这个指标就是F值。F值的计算公式为：<br>$$<br>F = \frac{(a ^ 2 + 1) \times P \times R}{a ^ 2 \times (P + R)}<br>$$</p>
<blockquote>
<p>P: Precision， R: Recall, a：权重因子</p>
<p>当a=1时，F值便是F1值，代表精确率和召回率的权重是一样的，是最常用的一种评价指标。</p>
<p>F1的计算公式为：$F1 = \frac{2 \times P \times R}{P + R}$</p>
</blockquote>
</li>
</ul>
<h3 id="2-2-混淆矩阵"><a href="#2-2-混淆矩阵" class="headerlink" title="2.2 混淆矩阵"></a>2.2 混淆矩阵</h3><p>混淆矩阵也称误差矩阵，是表示精度评价的一种标准格式，用n行n列的矩阵形式来表示。</p>
<p>具体评价指标有总体精度、制图精度、用户精度等，这些精度指标从不同的侧面反映了图像分类的精度。</p>
<p>下面是一个混淆矩阵，<code>Actual</code>代表真实值，<code>Predicted</code>代表预测值，预测的是标签号（因为是分类任务，主要对标签进行分类）。</p>
<blockquote>
<p>下面是我对TP、TN、FP、FN四个值的理解（助记）</p>
<p>TP：预测正确，预测成1</p>
<p>TN：预测正确，预测成0</p>
<p>FP：预测错误，预测成1</p>
<p>FN：预测错误，预测成0</p>
</blockquote>
<p><img src="808139430/image-20221230142020907.png" alt="混淆矩阵"></p>
<p>可以通过上面四个值计算相应的评估值，见下图。</p>
<p><img src="808139430/image-20221230143921870.png" alt="混淆矩阵计算评估指标"></p>
<blockquote>
<ul>
<li>准确率：预测正确的比例</li>
<li>精确率：在预测之后，在预测结果的某一结果上，正确的比例</li>
<li>召回率：在预测之前，真实值为某一结果上，正确的比例</li>
</ul>
</blockquote>
<h1 id="回归模型相关技巧"><a href="#回归模型相关技巧" class="headerlink" title="回归模型相关技巧"></a>回归模型相关技巧</h1><h2 id="1-下采样和上采样"><a href="#1-下采样和上采样" class="headerlink" title="1 下采样和上采样"></a>1 下采样和上采样</h2><p>在分类问题的数据中，很容易出现正反数据集数量存在极大的差距，这类数据直接用于训练不利于模型的构架，所以我们需要对数据进行些许处理。</p>
<p>很容易想到，合理的数据集应该是正反数据集数量应接近，那就存在两种策略：</p>
<p>下采样策略：把数量多的减少到与数量少的相近</p>
<p>上（过）采样策略：把数量少的增加到与数量多的相近</p>
<ul>
<li>下采样：</li>
</ul>
<p><img src="808139430/2.png" alt="img"></p>
<ul>
<li>上采样：SMOTE算法</li>
</ul>
<p><strong>步骤：</strong></p>
<p>（1）对于少数类中每一个样本x，以<strong>欧氏距离（两点之间距离）</strong>为标准计算它到少数类样本集中所有样本的距离，得到其<code>k</code>近邻（所有距离排序后前<code>k</code>小的距离）</p>
<p>（2）根据样本不平衡比例设置一个采样比例以确定采样倍率N，对于每一个少数类样本x，从其k近邻中随机选择若干个样本，假设选择的近邻为xn</p>
<p>（3）对于每一个随机选出的近邻xn，分别与原样本按照如下的公式构建新的样本。<br>$$<br>x_{new} = x + rand(0, 1) \times (\widetilde x - x)<br>$$</p>
<blockquote>
<p>$(\widetilde x - x)$ 相当于距离 $d_i$ （欧几里得距离），那么每个 $d_i$ 都可以生成一个新的数据。</p>
</blockquote>
<p><img src="808139430/image-20221230161807567.png" alt="SMOTE算法原理图"></p>
<h2 id="2-正则化惩罚"><a href="#2-正则化惩罚" class="headerlink" title="2 正则化惩罚"></a>2 正则化惩罚</h2><p>加上了正则化项能在一定程度上避免过拟合</p>
<h1 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h1><h2 id="1-概述-1"><a href="#1-概述-1" class="headerlink" title="1 概述"></a>1 概述</h2><h3 id="1-1-定义"><a href="#1-1-定义" class="headerlink" title="1.1 定义"></a>1.1 定义</h3><p>决策树是一种解决分类问题的算法，决策树算法采用树形结构，使用层层推理来实现最终的分类。</p>
<p>决策树即可以做分类，也可以做回归。它主要分为两种：<strong>分类树</strong> 和 <strong>回归树</strong>。</p>
<h3 id="1-2-决策树算法"><a href="#1-2-决策树算法" class="headerlink" title="1.2 决策树算法"></a>1.2 决策树算法</h3><ul>
<li>第一个决策树算法: CLS （Concept Learning System）</li>
<li>使决策树受到关注、成为机器学习主流技术的算法: ID3</li>
<li>最常用的决策树算法: C4.5</li>
<li>可以用于回归任务的决策树算法: CART （Classification and Regression Tree）</li>
<li>基于决策树的最强大算法: RF （Random Forest）</li>
</ul>
<h3 id="1-3-结构"><a href="#1-3-结构" class="headerlink" title="1.3 结构"></a>1.3 结构</h3><p>决策树由下面几种元素构成：</p>
<ul>
<li>根节点：包含样本的全集（全部训练数据）</li>
<li>内部节点：对应特征属性测试</li>
<li>叶节点：代表决策的结果</li>
</ul>
<p><img src="808139430/image-20221230164038527.png" alt="决策树结构"></p>
<p>决策树学习的<strong>目的</strong>是为了产生一棵泛化能力强的决策树</p>
<h2 id="2-决策树构建"><a href="#2-决策树构建" class="headerlink" title="2 决策树构建"></a>2 决策树构建</h2><h3 id="2-1-构建过程"><a href="#2-1-构建过程" class="headerlink" title="2.1 构建过程"></a>2.1 构建过程</h3><p>整体策略：自上而下分而治之</p>
<p>决策树的构建过程就是一个<strong>自根至叶的递归过程</strong>， 在每个中间结点寻找一个<strong>划分</strong>属性。</p>
<p>大致过程：</p>
<ul>
<li>开始：构建根节点，所有训练数据都放在根节点，选择x个最优特征，按着这一特征将训练数据集分割成子集，进入子节点。</li>
<li>所有子集按内部节点的属性递归地进行分割。</li>
<li>如果这些子集已经能够被基本正确分类，那么构建叶节点，并将这些子集分到所对应的叶节点去。</li>
<li>每个子集都被分到叶节点上，即都有了明确的类，这样就生成了一颗决策树。</li>
</ul>
<p>递归的三种停止条件：</p>
<ul>
<li>当前结点包含的样本全属于同一类别，无需划分；</li>
<li>当前属性集为空，或是所有样本在所有属性上取值相同，无法划分;</li>
<li>当前结点包含的样本集合为空，不能划分。</li>
</ul>
<h3 id="2-2-特征选择"><a href="#2-2-特征选择" class="headerlink" title="2.2 特征选择"></a>2.2 特征选择</h3><p><strong>信息熵</strong>：随机变量的不确定性。<br>$$<br>H(X) = - \sum p_i log_2 p_i \hspace{2em} \text{i = 1, 2, …, n}<br>$$</p>
<blockquote>
<p>例：</p>
<p>A集合 $[1, 1, 1, 1, 1, 1, 1, 1, 2, 2]$</p>
<p>B集合$[1, 2, 3, 4, 5, 6, 7, 8, 9, 1]$</p>
<p>A集合熵值低于B集合熵值，因为A集合中只有两种类别，B集合中类别比较多（结构比较乱），熵值就会比较大</p>
</blockquote>
<p><strong>信息增益：</strong> 表示特征X使得类Y的不确定性减少的程度（熵值减少），即当前划分对信息熵所造成的变化。</p>
<p>信息增益越大，表示特征a来划分所减少的熵最大，即提升最大，应当作为根节点。</p>
<h2 id="3-决策树算法"><a href="#3-决策树算法" class="headerlink" title="3 决策树算法"></a>3 决策树算法</h2><h3 id="3-1-ID3（信息增益）"><a href="#3-1-ID3（信息增益）" class="headerlink" title="3.1 ID3（信息增益）"></a>3.1 ID3（信息增益）</h3><p>下面是基于信息增益的ID3算法的实例：</p>
<p>我们有14天的数据，4个特征条件：<strong>天气，温度，湿度，是否有风</strong>。最终结果是去玩不玩。</p>
<p><img src="808139430/image-20221231110826312.png" alt="数据"></p>
<p><img src="808139430/image-20221231110929844.png" alt="划分方式"></p>
<p>上面有四种划分方式，我们需要判断谁来当根节点，根据的主要就是信息增益这个指标。下面计算信息增益来判断根节点。</p>
<p>本例暂且以<code>ent(a, b)</code>代表以下含义：（只有两种结果的时候的熵值计算）</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> math <span class="token keyword">import</span> log2
<span class="token keyword">def</span> <span class="token function">ent</span><span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token punctuation">:</span>
    tot <span class="token operator">=</span> a <span class="token operator">+</span> b
    x<span class="token punctuation">,</span> y <span class="token operator">=</span> a <span class="token operator">/</span> tot<span class="token punctuation">,</span> b <span class="token operator">/</span> tot
    <span class="token keyword">return</span> <span class="token operator">-</span><span class="token punctuation">(</span>x <span class="token operator">*</span> log2<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">+</span> y <span class="token operator">*</span> log2<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>总的数据中，9天玩，5天不玩，熵值为：<br>$$<br>-\frac{9}{14}log_2 \frac{9}{14} - \frac{5}{14}log_2 \frac{5}{14} = 0.940<br>$$<br>然后对4个特征逐个分析：</p>
<ul>
<li><p>outlook</p>
<ul>
<li><code>outlook = sunny</code>时，熵值为0.971，取值为sunny的概率为 $\frac{5}{14}$</li>
<li><code>outlook = overcast</code>时，熵值为0，取值为overcast的概率为 $\frac{4}{14}$</li>
<li><code>outlook = rainy</code>时，熵值为0.971，取值为rainy的概率为 $\frac{5}{14}$</li>
</ul>
<p>熵值为：<br>$$<br>\frac{5}{14} \times 0.971 + \frac{4}{14} \times 0 + \frac{5}{14} \times 0.971 = 0.693<br>$$<br>信息增益：系统熵值从0.940下降到0.693，增益为0.247。</p>
</li>
<li><p>temperture</p>
<ul>
<li><code>temperture = hot</code>时，熵值为1.0（<code>ent(2, 2)</code>），取值为hot的概率为$\frac{4}{14}$</li>
<li><code>temperture = mild</code>时，熵值为0.918（<code>ent(4, 2)</code>），取值为mild的概率为$\frac{6}{14}$</li>
<li><code>temperture = cool</code>时，熵值为0.81（<code>ent(3,1)</code>），取值为cool的概率为$\frac{4}{14}$</li>
</ul>
<p>熵值为：<br>$$<br>\frac{4}{14} \times 1.0 + \frac{6}{14} \times 0.918 + \frac{4}{14} \times 0.81 = 0.911<br>$$<br>信息增益：$Gain(S, temperture) = 0.940 - 0.911 = 0.029$</p>
</li>
<li><p>其他特征按照相同方法来做得到：</p>
</li>
</ul>
<p>$$<br>Gain(S，Outlook)=0.247  \<br>Gain(S, Humidity)=0.151  \<br>Gain(S, Wind)=0 .048 \<br>Gain(S,Temperature)=0 .029<br>$$</p>
<p>计算出所有的信息增益之后，选择<strong>有最大的信息增益的特征</strong>作为根节点。</p>
<p>下面找Sunny分支的决策树划分：</p>
<p>总的熵值<br>$$<br>-\frac{2}{5} \times log_2(\frac{2}{5}) - \frac{3}{5}log_2(\frac{3}{5}) = 0.97<br>$$<br>以剩下的三个特征进行分析：</p>
<ul>
<li><p>temperture</p>
<ul>
<li>temperture=hot，熵值为0，概率为$\frac{2}{5}$</li>
<li>temperture=mild，熵值为1.0，概率为$\frac{2}{5}$</li>
<li>temperture=cool，熵值为0，概率为$\frac{1}{5}$</li>
</ul>
<p>熵值为$\frac{2}{5}$</p>
<p>信息增益：$0.97-0.4 = 0.57$</p>
</li>
<li><p>humidy</p>
<ul>
<li>high，熵值为0，概率为$\frac{3}{5}$</li>
<li>normal，熵值为1，概率为$\frac{2}{5}$</li>
</ul>
<p>熵值为$\frac{2}{5}$</p>
<p>信息增益：$0.97 - 0.4 = 0.57$</p>
</li>
<li><p>windy</p>
<ul>
<li>false，熵值为0.918，概率为$\frac{3}{5}$</li>
<li>true，熵值为1，概率为$\frac{2}{5}$</li>
</ul>
<p>熵值为$0.951$</p>
<p>信息增益：$0.97 - 0.95 = 0.02$</p>
</li>
</ul>
<p>故选择humidy或wind划分</p>
<p>剩下的划分同理，最终决策树为</p>
<p><img src="808139430/image-20230208111655893.png" alt="最终决策树"></p>
<h3 id="3-2-C4-5（信息增益率）"><a href="#3-2-C4-5（信息增益率）" class="headerlink" title="3.2 C4.5（信息增益率）"></a>3.2 C4.5（信息增益率）</h3><blockquote>
<p>基于信息增益的决策树算法会有哪些问题：</p>
<p>如果有一个特征：id，代表样本的编号，以上述数据为例，id为从1到14，如果计算id特征的根节点，发现信息增益是最大的，因为每一个子节点的信息熵值都为0。</p>
</blockquote>
<p>信息增益率：（解决了ID3的问题，考虑自身熵，信息增益除以自身熵）<br>$$<br>\frac{G}{H(x)} \hspace{2em} \text{G:信息增益, H(x):熵值}<br>$$</p>
<h3 id="3-3-CART（GINI系数）"><a href="#3-3-CART（GINI系数）" class="headerlink" title="3.3 CART（GINI系数）"></a>3.3 CART（GINI系数）</h3><p>使用基尼系数作为衡量标准。<br>$$<br>Gini(p) = \sum \limits _{k = 1}^K p_k (1 - p_k) = 1 - \sum \limits _{k = 1}^K p_k^2<br>$$</p>
<h2 id="3-决策树剪枝"><a href="#3-决策树剪枝" class="headerlink" title="3 决策树剪枝"></a>3 决策树剪枝</h2><h3 id="3-1-预剪枝"><a href="#3-1-预剪枝" class="headerlink" title="3.1 预剪枝"></a>3.1 预剪枝</h3><p>在建立决策树边的时候进行剪枝的操作，比较使用实用。</p>
<p>剪枝策略：</p>
<ul>
<li>限制深度</li>
<li>限制叶子结点个数</li>
<li>限制叶子结点样本数</li>
<li>限制信息增益量等。</li>
</ul>
<h3 id="3-2-后剪枝"><a href="#3-2-后剪枝" class="headerlink" title="3.2 后剪枝"></a>3.2 后剪枝</h3><p>建立完决策树后进行剪枝操作。</p>
<h2 id="4-连续值和缺失值处理"><a href="#4-连续值和缺失值处理" class="headerlink" title="4 连续值和缺失值处理"></a>4 连续值和缺失值处理</h2><ul>
<li><p>连续值属性可取数值不是有限的，不能根据连续树形的可取值对节点进行划分。常见做法是：<strong>二分法</strong>对其进行离散化。</p>
</li>
<li><p>现实应用中，经常会遇到属性值<code>缺失</code>现象仅使用无缺失的样例，这是对数据的极大浪费使用带缺失值的样例，需解决：</p>
<ul>
<li>如何进行划分属性选择?</li>
<li>给定划分属性，若样本在该属性上的值缺失，如何进行划分?</li>
</ul>
<p>基本思路：<strong>样本赋权，权重划分</strong></p>
</li>
</ul>
<h1 id="集成算法"><a href="#集成算法" class="headerlink" title="集成算法"></a>集成算法</h1><h2 id="1-概述-2"><a href="#1-概述-2" class="headerlink" title="1 概述"></a>1 概述</h2><p>集成算法：Ensemble Learning</p>
<p>Bagging：训练多个分类器取平均<br>$$<br>f(x) = \frac{1}{M} \sum \limits_{m = 1}^M f_m(x)<br>$$<br>Boosting：从弱学习器开始加强，通过加权来训练。<br>$$<br>F_m(x) = F_{m - 1}(x) + argmin_h \sum \limits_{i = 1}^n L(y_i, F_{m - 1}(x_i) + h(x_i))<br>$$<br>Stacking：聚合多个分类或回归模型。</p>
<h2 id="2-Bagging模型-随机森林"><a href="#2-Bagging模型-随机森林" class="headerlink" title="2 Bagging模型-随机森林"></a>2 Bagging模型-随机森林</h2><p>其实就是并行训练一堆分类器（每个分类器互相独立）。典型代表为随机森林（多个决策树并行放在一起）。</p>
<blockquote>
<p>随机指的是：数据随机采样，特征随机选择</p>
<p>每个分类器喂的数据随机，数据的特征数随机。二重随机性，会让每个树基本都不一样，最终的结果也不一样。</p>
</blockquote>
<p>随机森林优势：</p>
<ul>
<li>可以处理高维度（feature多）数据，不用做特征选择</li>
<li>训练完之后，可以给出那些feature比较重要</li>
<li>容易做成并行化方法，速度快</li>
<li>可以进行可视化展示，便于分析</li>
</ul>
<h2 id="3-Boosting模型"><a href="#3-Boosting模型" class="headerlink" title="3 Boosting模型"></a>3 Boosting模型</h2><p>提升模型典型代表：AdaBoost，XgBoost</p>
<p>AdaBoost：会根据前一次的分类效果调整数据权重</p>
<h2 id="4-Stacking模型"><a href="#4-Stacking模型" class="headerlink" title="4 Stacking模型"></a>4 Stacking模型</h2><p>堆叠模型：可以堆叠各种各样的分类器（KNN，SVM，RF等）</p>
<p>分阶段进行：第一阶段得出各自的结果，第二阶段再利用前一阶段结果进行训练。</p>
<h1 id="贝叶斯算法"><a href="#贝叶斯算法" class="headerlink" title="贝叶斯算法"></a>贝叶斯算法</h1><p>贝叶斯公式：<br>$$<br>P(A | B) = \frac{P(B|A)P(A)}{P(B)}<br>$$</p>
<h2 id="1-1-实例：拼写纠正"><a href="#1-1-实例：拼写纠正" class="headerlink" title="1.1 实例：拼写纠正"></a>1.1 实例：拼写纠正</h2><p>用户输入一个不在词典中的单词，需要猜测用户真正想输入的单词。</p>
<p>我们要求的是<code>P(我们猜测用户想输入的单词|用户实际输入的单词)</code></p>
<p>假设用户实际输入的单词为<code>D</code>（Data）</p>
<p>我们有多个猜测：<code>P(h1 | D), P(h2 | D)</code>， 方便后续计算，统一为<code>P(h | D)</code><br>$$<br>P(h | D) = \frac{P(h) P(D | h)}{P(D)}<br>$$</p>
<blockquote>
<p>$P(h)$为单词在语料库中出现的概率（出现次数 / 总次数），我们叫做<strong>先验概率</strong>，这个概率可以算出来。</p>
<p>$P(D|h)$ 为我们将一个正确的词输入错误的概率。</p>
</blockquote>
<p>对于所有的猜测，$P(D)$ 都是一样的，所以可以忽略这个常数。</p>
<p>则<br>$$<br>P(h|D) \varpropto P(h)P(D|h)<br>$$</p>
<blockquote>
<p>$P(D|h)$可以根据某种指标来判定，可以看键盘上字母的编辑距离来算概率等等。</p>
</blockquote>
<p>如果计算出来多个结果预测概率是一样的，那么就可以使用<strong>先验概率</strong>来进行判断谁最优先。</p>
<h2 id="1-2-拼写检查器实现"><a href="#1-2-拼写检查器实现" class="headerlink" title="1.2 拼写检查器实现"></a>1.2 拼写检查器实现</h2><p>原理：<br>$$<br>argmaxc \ P(A|B) = argmaxc \  \frac{P(B|A) P(A)}{P(B)}<br>$$</p>
<p>$P(A|B)$：待求值，用户本想输入B的前提下，错输成A的概率</p>
<p>$P(A)$：文章中出现正确单词A的概率</p>
<p>$P(B|A)$：用户本想输入A的前提下，错输成B的概率</p>
<p>$P(B)$：文章中出现正确单词B的概率</p>
<p>$argmaxc$：用来枚举所有可能的A，并选取概率最大的那个</p>
<p>拼写检查器就是，输入一个单词，先判断这个单词是否存在于语料库中（是否正确），如果不在（可能语料库中没有，或者拼写错误），则需要根据编辑距离进行检查修正。</p>
<p><code>big.txt</code>文件：<a href="https://wwwi.lanzouo.com/i9s8t0ju5qzg" target="_blank" rel="noopener">https://wwwi.lanzouo.com/i9s8t0ju5qzg</a></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> re<span class="token punctuation">,</span> collections

<span class="token comment" spellcheck="true">#  将所有大写字母转化为小写，并且去掉特殊字符</span>
<span class="token keyword">def</span> <span class="token function">words</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token keyword">return</span> re<span class="token punctuation">.</span>findall<span class="token punctuation">(</span><span class="token string">'[a-z]+'</span><span class="token punctuation">,</span> text<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>features<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># 遇到从来没有见过的新词但语料库中未包含，概率模型中希望返回一个很小的概率，故出现次数设置为1</span>
    model <span class="token operator">=</span> collections<span class="token punctuation">.</span>defaultdict<span class="token punctuation">(</span><span class="token keyword">lambda</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> f <span class="token keyword">in</span> features<span class="token punctuation">:</span>
        model<span class="token punctuation">[</span>f<span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>
    <span class="token keyword">return</span> model


NWORDS <span class="token operator">=</span> train<span class="token punctuation">(</span>words<span class="token punctuation">(</span>open<span class="token punctuation">(</span><span class="token string">'big.txt'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 词频</span>
alphabet <span class="token operator">=</span> <span class="token string">'abcdefghijklmnopqrstuvwxyz'</span>

<span class="token comment" spellcheck="true"># 编辑距离为1的单词</span>
<span class="token keyword">def</span> <span class="token function">edits1</span><span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token punctuation">:</span>
    n <span class="token operator">=</span> len<span class="token punctuation">(</span>word<span class="token punctuation">)</span>
    <span class="token keyword">return</span> set<span class="token punctuation">(</span><span class="token punctuation">[</span>word<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span> i<span class="token punctuation">]</span> <span class="token operator">+</span> word<span class="token punctuation">[</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">+</span>   <span class="token comment" spellcheck="true"># deletion</span>
               <span class="token punctuation">[</span>word<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span> i<span class="token punctuation">]</span> <span class="token operator">+</span> word<span class="token punctuation">[</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+</span> word<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">+</span> word<span class="token punctuation">[</span>i <span class="token operator">+</span> <span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>n <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">+</span>  <span class="token comment" spellcheck="true"># transportation</span>
               <span class="token punctuation">[</span>word<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span> i<span class="token punctuation">]</span> <span class="token operator">+</span> c <span class="token operator">+</span> word<span class="token punctuation">[</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">:</span> <span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>n<span class="token punctuation">)</span> <span class="token keyword">for</span> c <span class="token keyword">in</span> alphabet<span class="token punctuation">]</span> <span class="token operator">+</span>  <span class="token comment" spellcheck="true"># alteration</span>
               <span class="token punctuation">[</span>word<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span> i<span class="token punctuation">]</span> <span class="token operator">+</span> c <span class="token operator">+</span> word<span class="token punctuation">[</span>i<span class="token punctuation">:</span> <span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>n <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token keyword">for</span> c <span class="token keyword">in</span> alphabet<span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># insertion</span>


<span class="token comment" spellcheck="true"># 编辑距离为2 的单词</span>
<span class="token keyword">def</span> <span class="token function">edits2</span><span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> set<span class="token punctuation">(</span>e2 <span class="token keyword">for</span> e1 <span class="token keyword">in</span> edits1<span class="token punctuation">(</span>word<span class="token punctuation">)</span> <span class="token keyword">for</span> e2 <span class="token keyword">in</span> edits1<span class="token punctuation">(</span>e1<span class="token punctuation">)</span><span class="token punctuation">)</span>


<span class="token comment" spellcheck="true"># 将那些正确的词作为候选词</span>
<span class="token keyword">def</span> <span class="token function">known</span><span class="token punctuation">(</span>words<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> set<span class="token punctuation">(</span>w <span class="token keyword">for</span> w <span class="token keyword">in</span> words <span class="token keyword">if</span> w <span class="token keyword">in</span> NWORDS<span class="token punctuation">)</span>


<span class="token comment" spellcheck="true"># 检查器函数，先判断是不是正确的拼写形式，如果不是则选出编辑距离为1的单词……</span>
<span class="token keyword">def</span> <span class="token function">correct</span><span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token punctuation">:</span>
    candidates <span class="token operator">=</span> known<span class="token punctuation">(</span><span class="token punctuation">[</span>word<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">or</span> known<span class="token punctuation">(</span>edits1<span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">or</span> known<span class="token punctuation">(</span>edits2<span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">or</span> <span class="token punctuation">[</span>word<span class="token punctuation">]</span>
    <span class="token keyword">return</span> max<span class="token punctuation">(</span>candidates<span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword">lambda</span> w<span class="token punctuation">:</span> NWORDS<span class="token punctuation">[</span>w<span class="token punctuation">]</span><span class="token punctuation">)</span>


<span class="token keyword">print</span><span class="token punctuation">(</span>correct<span class="token punctuation">(</span><span class="token string">'mach'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="1-3-新闻分类"><a href="#1-3-新闻分类" class="headerlink" title="1.3 新闻分类"></a>1.3 新闻分类</h2><p>之后用到了再补，短时间不会写。</p>
<h1 id="SVM支持向量机"><a href="#SVM支持向量机" class="headerlink" title="SVM支持向量机"></a>SVM支持向量机</h1><h2 id="1-概述-3"><a href="#1-概述-3" class="headerlink" title="1 概述"></a>1 概述</h2><p>Support Vector Machine是一种二分类模型，它的基本模型是定义在特征空间上的<strong>间隔最大的线性分类器</strong></p>
<p>SVM学习的基本想法是求解能够正确划分训练数据集并且几何间隔最大的分离超平面。如下图所示， $wx+b=0$ 即为分离超平面，对于线性可分的数据集来说，这样的超平面有无穷多个（即感知机），但是几何间隔最大的分离超平面却是唯一的。</p>
<p><img src="808139430/image-20230102144808362.png" alt="支持向量机"></p>
<h2 id="2-推导"><a href="#2-推导" class="headerlink" title="2 推导"></a>2 推导</h2><h3 id="2-1-距离"><a href="#2-1-距离" class="headerlink" title="2.1 距离"></a>2.1 距离</h3><p>正常三维条件下点$(x_0, y_0, z_0)$到平面$Ax + By + Cz + D = 0$的距离公式（高中知识）：<br>$$<br>\frac{\vert Ax_0 + By_0 + Cz_0 + D \vert}{\sqrt{A^2 + B^2 + C^2}}<br>$$<br>推导分析过程：</p>
<p>平面方程： $ax + by + cz = d$ ，平面外一点$P(x_0, y_0, z_0)$</p>
<p><img src="808139430/image-20230102153203878.png" alt="示意图"></p>
<p>PQ垂直平面，即为求PQ的长度，但不知Q点的具体数据。</p>
<p>故构造一个平面上的点$P^{‘}(x_1, y_1, z_1)$，问题即转化为求$\overrightarrow {P^{‘}P}$ 在法向量N上面的分量，即$\overrightarrow {P^{‘}P}$ 与N相同方向的单位向量的点积。</p>
<p><img src="808139430/image-20230102153230935.png" alt="示意图"></p>
<p>设距离为D。</p>
<p><img src="808139430/1203675-20180109152428254-718844217.png" alt="距离公式推导"></p>
<p>现在考虑一般情况：</p>
<p>求平面外一点 $x$ 到平面$w^T x + b = 0$ 的距离：</p>
<blockquote>
<p>结论：平面$Ax + By + Cz + D = 0$的法向量为$(A, B, C)$</p>
</blockquote>
<p><img src="808139430/image-20230102154354917.png" alt="示意图"></p>
<p>同上述原理：</p>
<p>距离就为<br>$$<br>distance(x, b, w) = \vert \frac{w^T}{\vert \vert w \vert \vert}(x - x^{‘}) \vert = \frac{1}{\vert \vert w \vert \vert} \vert w^Tx + b \vert<br>$$</p>
<blockquote>
<p>上述公式进行了代入，将$x^{‘}$代入平面方程得$w^Tx^{‘} = -b$</p>
</blockquote>
<h3 id="2-2-数据"><a href="#2-2-数据" class="headerlink" title="2.2 数据"></a>2.2 数据</h3><p>数据集：$(x_1, y_1)(x_2, y_2)…(x_n, y_n)$</p>
<p>$Y$ 为样本的类别：当$X$ 为正例时，$Y = +1$，当$X$为负例时，$Y = -1$</p>
<p>决策方程：$y(x) = w^T \Phi(x) + b$ （其中$\Phi(x)$是对数据做了核变换，可以暂时理解为$x$）<br>$$<br>\begin{cases}<br>y(x_i) &gt; 0 \Leftrightarrow y_i = +1 \\<br>y(x_i) &lt; 0 \Leftrightarrow y_i = -1<br>\end{cases}<br>\Longrightarrow<br>y_i y(x_i) &gt; 0<br>$$</p>
<h3 id="2-3-目标函数求解"><a href="#2-3-目标函数求解" class="headerlink" title="2.3 目标函数求解"></a>2.3 目标函数求解</h3><blockquote>
<p>我们要求的就是找到一个线性划分（比如说直线），使得离该线最近的点最远。</p>
</blockquote>
<p>将点到直线距离进行转化（化简）：<br>$$<br>\frac{y_i \cdot (w^T \cdot \Phi(x) + b)}{\vert \vert w \vert \vert}<br>$$</p>
<blockquote>
<p>$y_i y(x_i) &gt; 0$ 直接乘上$y_i$ 将绝对值去掉，$|y_i| = 1$，并不影响值大小</p>
</blockquote>
<p>放缩变换：对于决策方程（w, b）可以通过放缩变换使其结果值$|Y| \geq 1$ ，则<br>$$<br>y_i \cdot (w^T \cdot \Phi(x_i) + b) \geq 1<br>$$</p>
<blockquote>
<p>缩放之前w和b有无数组解，缩放之后w和b只有一组解。</p>
</blockquote>
<p>优化目标：<br>$$<br>\mathop{arg\  max} \limits_{w, b} \bigg\{ \frac{1}{||w||} \mathop{min} \limits_i \Big \{ y_i \cdot (w^T \cdot \Phi(x_i) + b)\Big \} \bigg\}<br>$$</p>
<blockquote>
<p>$\mathop{min} \limits_i \Big \{ y_i \cdot (w^T \cdot \Phi(x_i) + b) \Big \}$ 是求所有样本点到平面的最小距离的那个点</p>
<p>$\mathop{argmax} \limits_{w,b}$ 是<strong>最大化到平面最小距离的点的距离，此时的w,b的值</strong></p>
<p>由于$y_i \cdot (w^T \cdot \Phi(x_i) + b) \geq 1$， 故最小值为1，只需要考虑 $\mathop{arg\  max} \limits_{w, b} \frac{1}{||w||}$</p>
</blockquote>
<p>当前目标变为：$\mathop{max} \limits_{w, b} \frac{1}{||w||}$，即求$||w||$的最小值，但有约束条件 $y_i \cdot (w^T \cdot \Phi(x_i) + b) \geq 1$</p>
<p>将求极大值转化为求极小值的问题，求$\frac{1}{2}||w||^2$ 的最小值。</p>
<p>需要使用<strong>拉格朗日乘子法</strong>：（此处不做证明，直接给出结论）<br>$$<br>L(w, b, \alpha) = \frac{1}{2}||w||^2 - \sum \limits_{i = 1}^n \alpha_i (y_i \cdot (w^T \cdot \Phi(x_i) + b) - 1)<br>$$</p>
<blockquote>
<p>上式需要满足约束条件：$y_i \cdot (w^T \cdot \Phi(x_i) + b) \geq 1$</p>
<p>满足KKT条件的点未必是局部（全局）最优点（还可能是局部极大和鞍点），但局部（全局）最优点必然满足KKT条件。对于凸优化问题，满足KKT条件的解直接就是全局最优解<br>$$<br>最优解的必要条件:<br>\begin{cases}<br>\nabla L(\mathbf{x}, \lambda) = \nabla f(\mathbf{x}) + \lambda \nabla g(\mathbf{x}) = 0 \\<br>\lambda \ge 0 \\<br>\lambda g(\mathbf{x}) = 0 (互补松弛)\\<br>g(\mathbf{x}) \le 0 (原约束)<br>\end{cases}<br>$$</p>
<p>推导可参考：<a href="https://blog.csdn.net/v_july_v/article/details/7624837" target="_blank" rel="noopener">https://blog.csdn.net/v_july_v/article/details/7624837</a> </p>
<p>原理可参考：<a href="https://zhuanlan.zhihu.com/p/31886934" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/31886934</a> </p>
</blockquote>
<p><img src="808139430/image-20230102224841617.png" alt="求解过程"></p>
<p><img src="808139430/image-20230102225344026.png" alt="求解过程"></p>
<p><img src="808139430/image-20230102225422893.png" alt="求解过程"></p>
<h2 id="3-SVM实例"><a href="#3-SVM实例" class="headerlink" title="3 SVM实例"></a>3 SVM实例</h2><p>有三个数据：3个点，正例$x_1(3, 3), x_2(4, 3)$， 负例$x_3(1, 1)$，（数据是二维数据）对其进行二分类。</p>
<p>首先需要求解下式的最小值：<br>$$<br>\frac{1}{2}\sum \limits_{i = 1}^n \sum \limits _{j = 1}^n \alpha_i \alpha_j y_i y_j (x_i \cdot x_j) - \sum \limits_{i = 1}^n\alpha_i \hspace{3em} (1)<br>$$</p>
<blockquote>
<p>注意：$x_i \cdot x_j$ 的运算是点积运算。</p>
<p>约束条件：<br>$$<br>\alpha_1 + \alpha_2 - \alpha_3 = 0 \\<br>\alpha_i \geq 0, \hspace{2em} i = 1, 2, 3<br>$$</p>
</blockquote>
<p><img src="808139430/image-20230103144319179.png" alt="图像示意"></p>
<p>将对应的数据带入（1）式，得：<br>$$<br>\frac{1}{2} \Big( 18 \alpha_1^2 + 25\alpha_2^2 + 2 \alpha_3^2 + 42\alpha_1\alpha_2 - 12\alpha_1\alpha_3 - 14\alpha_2\alpha_3 \Big) - \alpha_1 - \alpha_2 - \alpha_3<br>$$<br>由于$\alpha_1 + \alpha_2 = \alpha_3$，化简得：<br>$$<br>4 \alpha_1 ^ 2 + \frac{13}{2} \alpha_2^2 + 10\alpha_1\alpha_2 - 2\alpha_1 - 2\alpha_2<br>$$<br>分别对$\alpha_1,\alpha_2$求偏导，偏导等于0得<br>$$<br>\begin{cases}<br>\alpha_1 = 1.5 \\<br>\alpha_2 = -1<br>\end{cases}<br>$$<br>发现不满足约束条件$\alpha_i \geq 0$，故解应在边界上。分别让两个值等于0求解<br>$$<br>\begin{cases}<br>\alpha_1 = 0 \\<br>\alpha_2 = -\frac{2}{13}<br>\end{cases}<br>(\times)<br>\hspace{4em}<br>\begin{cases}<br>\alpha_1 = 0.25 \\<br>\alpha_2 = 0<br>\end{cases}<br>(\checkmark)<br>$$<br>第一组解不满足，故最小值在$(0.25, 0, 0.25)$处取得。</p>
<p>将$\alpha$结果带求解$w = \sum \limits_{i = 1}^n \alpha_i y_i \Phi(x_i)$，$\Phi(x_i)$以$x_i$来代替<br>$$<br>w = \frac{1}{4} \times 1 \times (3,3) + \frac{1}{4} \times (-1) \times(1,1) = (\frac{1}{2}, \frac{1}{2})<br>\\<br>b = y_i - \sum \limits_{i = 1}^n a_i y_i (x_i x_j) = 1 - (\frac{1}{4} \times 1 \times 18  + \frac{1}{4} \times (-1) \times 6) = -2<br>$$<br>故平面方程为：<br>$$<br>0.5 x_1 + 0.5 x_2 - 2 = 0<br>$$</p>
<blockquote>
<p>因为$w = \sum \limits_{i = 1}^n \alpha_i y_i \Phi(x_i)$</p>
<p>支持向量的$\alpha$值不等于0，$\alpha = 0$的向量不是支持向量，对最终结果没有影响。</p>
<p>支持向量就是那些对最终结果起作用的向量，也可以当做是边界上的向量。</p>
</blockquote>
<h2 id="4-软间隔"><a href="#4-软间隔" class="headerlink" title="4 软间隔"></a>4 软间隔</h2><p>数据中有时候会有一些噪音点，如果考虑它们结果可能不会很好。</p>
<p>之前讨论的是要求所有样本点全部满足约束（这是硬间隔），而实际情况中这显然是不太可能的，软间隔则是允许某些样本点不满足约束。</p>
<p>为解决该问题，引入松弛因子：$y_i(w \cdot x_i + b) \geq 1 - \xi_i$</p>
<p>新的目标函数：<br>$$<br>\mathop{min}\limits_{w, b, \xi_i} \frac{1}{2} ||w||^2 + C \sum \limits _{i = 1}^n \xi_i<br>$$</p>
<blockquote>
<p>C是我们需要指定的一个参数</p>
<p>当C趋近于很大时：意味着分类严格不能有错误</p>
<p>当C趋近于很小时：意味着可以由更大的错误容忍</p>
</blockquote>
<p>解法基本一样：</p>
<p><img src="808139430/image-20230103153918323.png" alt="解法"></p>
<h2 id="5-SVM核变换"><a href="#5-SVM核变换" class="headerlink" title="5 SVM核变换"></a>5 SVM核变换</h2><p>将低维不可分映射到高维，找到一种变换方法，即为$\phi(x)$</p>
<p>高斯核函数：<br>$$<br>K(X, Y) =  exp \bigg\{ -\frac{||X-Y||^2}{2\sigma^2} \bigg\}<br>$$</p>
<h2 id="6-基于sklearn求解SVM"><a href="#6-基于sklearn求解SVM" class="headerlink" title="6 基于sklearn求解SVM"></a>6 基于sklearn求解SVM</h2><p>参考 <a href="https://blog.csdn.net/weixin_42600072/article/details/88644229" target="_blank" rel="noopener">https://blog.csdn.net/weixin_42600072/article/details/88644229</a></p>
<h1 id="聚类算法"><a href="#聚类算法" class="headerlink" title="聚类算法"></a>聚类算法</h1><p>性能度量：</p>
<ul>
<li>外部指标<ul>
<li><code>jaccard</code>系数（简称<code>JC</code>）</li>
<li><code>FM</code>指数（简称<code>FMI</code>）</li>
<li><code>Rand</code>指数（简称<code>RI</code>）</li>
</ul>
</li>
<li>内部指标<ul>
<li><code>DB</code>指数（简称<code>DBI</code>）</li>
<li><code>Dunn</code>指数（简称<code>DI</code>）</li>
</ul>
</li>
</ul>
<p>距离计算：</p>
<ul>
<li>$L_p$ 范数</li>
<li>欧氏距离</li>
<li>曼哈顿距离</li>
</ul>
<p>分类：</p>
<ul>
<li>原型聚类：<code>k-means</code>算法，学习向量量化（有监督学习），高斯混合聚类 都是此类型算法</li>
</ul>
<blockquote>
<p>假设聚类结构能够通过一组原型刻画，然后对原型进行迭代更新求解。</p>
</blockquote>
<ul>
<li><p>密度聚类：DBSCAN</p>
</li>
<li><p>层次聚类：AGNES</p>
<p>试图在不同层次上对数据集进行划分，分为自底向上的聚合策略和自顶向下的分拆策略</p>
</li>
</ul>
<p>聚簇之间的距离的计算：最小距离，最大距离和平均距离（两个簇中样本点对距离之和取平均）</p>
<p>AGNES算法被相应称为：单链接算法（以最小距离为准），全链接算法（以最大距离为准）和均链接算法</p>
<blockquote>
<p>以单链接算法为例：</p>
<ul>
<li>初始时每个样本点看做一个簇，找到所有簇对中最小的距离，将他们合并为一个簇，此时合并的簇与其他簇的距离更新为两个点到其他簇距离的最小值。</li>
<li>上面的步骤为循环里面的步骤，接着进行下一次循环，找到所有簇中最短的距离，然后将他们合并，合并后更新簇之间的距离为【合并簇中的所有点到其他簇距离的最小值】，一直进行上述循环操作，直到达到指定簇的数量再停止循环。</li>
</ul>
</blockquote>
<h2 id="K-MEANS算法"><a href="#K-MEANS算法" class="headerlink" title="K-MEANS算法"></a>K-MEANS算法</h2><h3 id="1-概述-4"><a href="#1-概述-4" class="headerlink" title="1 概述"></a>1 概述</h3><p>聚类概念：这是个无监督问题（没有标签数据），目的是将相似的东西分到一组。</p>
<p>通常使用的算法是K-MEANS算法</p>
<blockquote>
<p>K-MEANS算法：</p>
<ul>
<li>需要指定簇的个数，即K值</li>
<li>质心：数据的均值，即向量各维取平均即可</li>
<li>距离的度量：常用欧几里得距离和余弦相似度（先标准化，让数据基本都是在一个比较小的范围内浮动）</li>
<li>优化目标：$min\sum \limits_{i = 1}^K \sum \limits_{x \in C_i} dist(c_i, x)^2$ （对于每一个簇让每一个样本到中心点的距离越小越好，$c_i$代表中心点）</li>
</ul>
</blockquote>
<h3 id="2-K-MEANS流程"><a href="#2-K-MEANS流程" class="headerlink" title="2 K-MEANS流程"></a>2 K-MEANS流程</h3><p>假设平面上有一系列样本点，现在需要将其进行分组。</p>
<p>选定<code>K=2</code>，即将这些数据点分成两个组别。</p>
<ul>
<li>随机选择两个质心（分别代表两个簇），计算所有样本点到两个质心的距离。每个样本点会计算出到两个质心的距离，那么选择最小的距离，这个样本点就归属于哪个簇。</li>
<li>然后对于两个簇的所有样本点分别算出对应的质心（这两个质心便充当新的质心），再对所有样本点计算到两个新的质心的距离，还是选择最小的距离，那么这个样本点就归属于哪个簇。</li>
<li>最终直到两个簇所属的样本点不在发生变化。</li>
</ul>
<blockquote>
<p><a href="https://www.bilibili.com/video/BV1bt411i77G?p=101&vd_source=bb4ca29d8dfb2e3c28c10bb09f4b962e" target="_blank" rel="noopener">K-MEANS工作流程视频参考</a></p>
</blockquote>
<h3 id="3-优缺点"><a href="#3-优缺点" class="headerlink" title="3 优缺点"></a>3 优缺点</h3><p>优点：</p>
<ul>
<li>简单快速，适合常规数据集</li>
</ul>
<p>缺点：</p>
<ul>
<li>K值难以确定</li>
<li>复杂度与样本呈线性关系</li>
<li>很难发现任意形状的簇</li>
<li>初始的点影响很大</li>
</ul>
<blockquote>
<p> <a href="https://www.naftaliharris.com/blog/visualizing-k-means-clustering/" target="_blank" rel="noopener">K-MEANS可视化演示</a></p>
</blockquote>
<h3 id="4-K-MEANS进行图像压缩"><a href="#4-K-MEANS进行图像压缩" class="headerlink" title="4 K-MEANS进行图像压缩"></a>4 K-MEANS进行图像压缩</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> skimage <span class="token keyword">import</span> io
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>cluster <span class="token keyword">import</span> KMeans
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

image <span class="token operator">=</span> io<span class="token punctuation">.</span>imread<span class="token punctuation">(</span><span class="token string">"1.jpg"</span><span class="token punctuation">)</span>
io<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>image<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># io.show()  # 显示图片</span>

rows <span class="token operator">=</span> image<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
cols <span class="token operator">=</span> image<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>image<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

image <span class="token operator">=</span> image<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>rows <span class="token operator">*</span> cols<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
kmeans <span class="token operator">=</span> KMeans<span class="token punctuation">(</span>n_clusters<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span> n_init<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> max_iter<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 簇128, 最大迭代次数100</span>
kmeans<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>image<span class="token punctuation">)</span>

clusters <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>kmeans<span class="token punctuation">.</span>cluster_centers_<span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span>
labels <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>kmeans<span class="token punctuation">.</span>labels_<span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span>
labels <span class="token operator">=</span> labels<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>rows<span class="token punctuation">,</span> cols<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>clusters<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
np<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token string">'test.npy'</span><span class="token punctuation">,</span> clusters<span class="token punctuation">)</span>
io<span class="token punctuation">.</span>imsave<span class="token punctuation">(</span><span class="token string">'compressed.jpg'</span><span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="DBSCAN算法"><a href="#DBSCAN算法" class="headerlink" title="DBSCAN算法"></a>DBSCAN算法</h2><h3 id="1-概述-5"><a href="#1-概述-5" class="headerlink" title="1 概述"></a>1 概述</h3><p>DBSCAN（Density-Based Spatial Clustering of Applications with Noise，具有噪声的基于密度的聚类方法）是一种<strong>基于密度的空间聚类算法</strong>。该算法将具有足够密度的区域划分为簇，并在具有噪声的空间数据库中发现任意形状的簇，DBSCAN算法将<code>簇</code>定义为密度相连的点的最大集合。</p>
<p>核心对象：若某个点的密度达到算法设定的阈值则称其为核心点。（即<code>r</code>邻域内的点的数量不小于<code>minPts</code>）</p>
<p>基于以上密度的定义，我们可以将样本集中的点划分为以下三类：</p>
<ul>
<li><strong>核心点</strong>：在半径r区域内，含有超过MinPts数目（最小数目）的点，称为核心点；</li>
<li><strong>边界点</strong>：在半径r区域内，点的数量小于MinPts数目，但是是核心点的直接邻居；</li>
<li><strong>噪声点</strong>：既不是核心点也不是边界点的点</li>
</ul>
<blockquote>
<p>噪声点是不会被聚类纳入的点，边界点与核心点组成聚类的“簇”。</p>
</blockquote>
<p>一些概念：</p>
<ul>
<li><strong>直接密度可达（密度直达）</strong>：如果p在q的r领域内，且<strong>q是一个核心点对象</strong>，则称对象p从对象q出发时直接密度可达，反之不一定成立，即密度直达不满足对称性。</li>
<li><strong>密度可达</strong>：如果存在一个对象链q–&gt;e–&gt;a–&gt;k–&gt;l–&gt;p，任意相邻两个对象间都是密度直达的，则称对象p由对象q出发密度可达。密度可达满足传递性。</li>
<li><strong>密度相连</strong>：对于 $x_i$ 和 $x_j$ ,如果存在核心对象样本 $x_k$ ，使 $x_i$ 和 $x_j$ 均由 $x_k$ 密度可达，则称 $x_i$ 和 $x_j$ 密度相连。<strong>密度相连关系满足对称性</strong>。</li>
</ul>
<blockquote>
<p>核心点能够连通（密度可达），它们构成的以r为半径的圆形邻域相互连接或重叠，这些连通的核心点及其所处的邻域内的全部点构成一个簇。</p>
</blockquote>
<h3 id="2-原理"><a href="#2-原理" class="headerlink" title="2 原理"></a>2 原理</h3><ol>
<li>DBSCAN通过检查数据集中每个点的r邻域来搜索簇，如果点p的r邻域包含多于MinPts个点，则创建一个以p为核心对象的簇；</li>
<li>然后， DBSCAN迭代的聚集从这些核心对象直接密度可达的对象，这个过程可能涉及一些密度可达簇的合并；</li>
<li>当没有新的带你添加到任何簇时，迭代过程结束。</li>
</ol>
<p>优缺点：</p>
<ul>
<li><p>优点：基于密度定义，可以对抗噪声，能处理任意形状和大小的簇</p>
</li>
<li><p>缺点：当簇的密度变化太大时候，聚类得到的结果会不理想；对于高维问题，密度定义也是一个比较麻烦的问题。</p>
</li>
</ul>
<h3 id="3-实现"><a href="#3-实现" class="headerlink" title="3 实现"></a>3 实现</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> datasets
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>colors

<span class="token comment" spellcheck="true"># 创建Figure</span>
fig <span class="token operator">=</span> plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 用来正常显示中文标签</span>
matplotlib<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">'font.sans-serif'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span>u<span class="token string">'SimHei'</span><span class="token punctuation">]</span>
<span class="token comment" spellcheck="true"># 用来正常显示负号</span>
matplotlib<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">'axes.unicode_minus'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">False</span>

X1<span class="token punctuation">,</span> y1 <span class="token operator">=</span> datasets<span class="token punctuation">.</span>make_circles<span class="token punctuation">(</span>n_samples<span class="token operator">=</span><span class="token number">5000</span><span class="token punctuation">,</span> factor<span class="token operator">=</span><span class="token punctuation">.</span><span class="token number">6</span><span class="token punctuation">,</span>
                                      noise<span class="token operator">=</span><span class="token punctuation">.</span><span class="token number">05</span><span class="token punctuation">)</span>
X2<span class="token punctuation">,</span> y2 <span class="token operator">=</span> datasets<span class="token punctuation">.</span>make_blobs<span class="token punctuation">(</span>n_samples<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span> n_features<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>
                             centers<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.2</span><span class="token punctuation">,</span><span class="token number">1.2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> cluster_std<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>random_state<span class="token operator">=</span><span class="token number">9</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 原始点的分布</span>
ax1 <span class="token operator">=</span> fig<span class="token punctuation">.</span>add_subplot<span class="token punctuation">(</span><span class="token number">311</span><span class="token punctuation">)</span>
X <span class="token operator">=</span> np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span><span class="token punctuation">(</span>X1<span class="token punctuation">,</span> X2<span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> marker<span class="token operator">=</span><span class="token string">'o'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span>u<span class="token string">'原始数据分布'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>sca<span class="token punctuation">(</span>ax1<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># K-means聚类</span>
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>cluster <span class="token keyword">import</span> KMeans
ax2 <span class="token operator">=</span> fig<span class="token punctuation">.</span>add_subplot<span class="token punctuation">(</span><span class="token number">312</span><span class="token punctuation">)</span>
y_pred <span class="token operator">=</span> KMeans<span class="token punctuation">(</span>n_clusters<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">9</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit_predict<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span>y_pred<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span>u<span class="token string">'K-means聚类'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>sca<span class="token punctuation">(</span>ax2<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># DBSCAN聚类</span>
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>cluster <span class="token keyword">import</span> DBSCAN
ax3 <span class="token operator">=</span> fig<span class="token punctuation">.</span>add_subplot<span class="token punctuation">(</span><span class="token number">313</span><span class="token punctuation">)</span>
y_pred <span class="token operator">=</span> DBSCAN<span class="token punctuation">(</span>eps <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">,</span> min_samples <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit_predict<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span>y_pred<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span>u<span class="token string">'DBSCAN聚类'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>sca<span class="token punctuation">(</span>ax3<span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h1 id="PCA主成分分析"><a href="#PCA主成分分析" class="headerlink" title="PCA主成分分析"></a>PCA主成分分析</h1><p>Principal Component Analysis：降维中最常用的一种手段，PCA的主要思想是将<code>n</code>维特征映射到<code>k</code>维上，这<code>k</code>维是全新的正交特征也被称为主成分，是在原有<code>n</code>维特征的基础上重新构造出来的<code>k</code>维特征。</p>
<p>PCA的工作就是从原始的空间中顺序地找一组相互正交的坐标轴，新的坐标轴的选择与数据本身是密切相关的。其中，第一个新坐标轴选择是原始数据中方差最大的方向，第二个新坐标轴选取是与第一个坐标轴正交的平面中使得方差最大的，第三个轴是与第1,2个轴正交的平面中方差最大的。依次类推，可以得到n个这样的坐标轴。通过这种方式获得的新的坐标轴，我们发现，大部分方差都包含在前面k个坐标轴中，后面的坐标轴所含的方差几乎为0。于是，我们可以忽略余下的坐标轴，只保留前面k个含有绝大部分方差的坐标轴。</p>
<p>通过计算数据矩阵的协方差矩阵，然后得到协方差矩阵的特征值特征向量，选择特征值最大(即方差最大)的k个特征所对应的特征向量组成的矩阵。这样就可以将数据矩阵转换到新的空间当中，实现数据特征的降维。</p>
<p>由于得到协方差矩阵的特征值特征向量有两种方法：特征值分解协方差矩阵、奇异值分解协方差矩阵，所以PCA算法有两种实现方法：</p>
<ul>
<li><p>基于特征值分解协方差矩阵实现PCA算法</p>
</li>
<li><p>基于SVD分解协方差矩阵实现PCA算法</p>
</li>
</ul>
<h2 id="1-基变换"><a href="#1-基变换" class="headerlink" title="1 基变换"></a>1 基变换</h2><p>目标：提取最有价值的信息（基于方差）</p>
<ul>
<li><p>基概念：例如在二维坐标系中，向量（3，4）也可表示为线性组合$x(1, 0) + y(0, 1)$，而$(0,1)(1,0)$叫做二维空间的一组基。</p>
</li>
<li><p>基变换</p>
<ul>
<li><p>要求：基是正交的（内积/点积为0，或者说互相垂直，线性无关）</p>
</li>
<li><p>变换：数据与第一个基做内积运算，结果作为第一个新的坐标分量；数据与第二个基做内积运算，结果作为第二个新的坐标分量。</p>
</li>
</ul>
</li>
</ul>
<p>比如$(3,2)$映射到基的坐标：<br>$$<br>\begin{pmatrix}<br>\frac{1}{\sqrt{2}} &amp; \frac{1}{\sqrt{2}} \\<br>-\frac{1}{\sqrt{2}} &amp; \frac{1}{\sqrt{2}}<br>\end{pmatrix}<br>\begin{pmatrix}<br>3 \\<br>2<br>\end{pmatrix}<br>=<br>\begin{pmatrix}<br>\frac{5}{\sqrt 2} \\<br>-\frac{1}{\sqrt 2}<br>\end{pmatrix}<br>$$</p>
<ul>
<li>基变换一般公式：</li>
</ul>
<p>$$<br>\begin{pmatrix}<br>p_1 \\<br>p_2 \\<br>\vdots \\<br>p_n<br>\end{pmatrix}<br>\begin{pmatrix}<br>a_1 &amp; a_2 &amp; \cdots &amp;a_m<br>\end{pmatrix}<br>=<br>\begin{pmatrix}<br>p_1a_1 &amp; p_1a_2 &amp; \cdots &amp; p_1a_m \\<br>p_2a_1 &amp; p_2a_2 &amp; \cdots &amp; p_2a_m \\<br>\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\<br>p_na_1 &amp; p_na_2 &amp; \cdots &amp; p_na_m \\<br>\end{pmatrix}<br>$$</p>
<blockquote>
<p>等式左边的两个矩阵中，左边是基，右边是数据。</p>
<p>两个矩阵相乘的意义是将右边的矩阵中的每一列列向量变换到左边矩阵中每一行行向量为基所表示的空间中去。</p>
</blockquote>
<h2 id="2-协方差矩阵"><a href="#2-协方差矩阵" class="headerlink" title="2 协方差矩阵"></a>2 协方差矩阵</h2><p>我们希望选择一个方向（基）：数据能够保留更多的原始信息，也可以说希望经过某个基投影后的投影值尽可能分散。（雾</p>
<p>方差：<br>$$<br>Var(a) = \frac{1}{m} \sum \limits_{i = 1}^m (a_i - \mu)^2<br>$$<br>寻找一个一维基，使得所有数据变换为这个基上的坐标表示后，<strong>方差值最大</strong>（分散）。</p>
<p>协方差：（假设均值为0时）（对于标签$a_i, b_i$，如果两个相似度越大，协方差越大）<br>$$<br>Cov(a, b) = \frac{1}{m} \sum \limits_{i = 1}^m a_ib_i<br>$$</p>
<blockquote>
<p>如果单纯选择方差最大的方向，后续方向应该会和方差最大的方向接近重合。</p>
<p>解决方案：为了让两个子段尽可能表示更多的原始信息，我们是不希望他们之间存在（线性）相关性的。</p>
<p>可以用两个字段的协方差表示相关性，当协方差为0时，代表两个字段是相互独立的。</p>
</blockquote>
<p>题意：将一组N维向量降为K维，目标是选择K个单位的正交基，使原始数据变换到这组基上面后，各字段两两之间协方差为0，字段方差尽可能大。</p>
<p>$$<br>\text{特征数据}X =<br>\begin{pmatrix}<br>a_1 &amp; a_2 &amp; \cdots &amp; a_m \\<br>b_1 &amp; b_2 &amp; \cdots &amp; b_m<br>\end{pmatrix}<br>$$<br>协方差矩阵：<br>$$<br>\frac{1}{m}XX^T =<br>\begin{pmatrix}<br>\frac{1}{m}\sum \limits_{i = 1}^m a_i^2  &amp; \frac{1}{m}\sum \limits_{i = 1}^ma_ib_i \\<br>\frac{1}{m}\sum \limits_{i = 1}^m a_ib_i &amp; \frac{1}{m}\sum \limits_{i = 1}^mb_i^2<br>\end{pmatrix}<br>$$</p>
<blockquote>
<p>矩阵对角线上的两个元素分别为两个字段的方差（假设均值为0），而其他元素是a和b的协方差。</p>
</blockquote>
<h2 id="3-优化"><a href="#3-优化" class="headerlink" title="3 优化"></a>3 优化</h2><p>接下来就是希望让协方差矩阵的除对角线位置的元素为0（协方差为0），就是进行对角化操作。</p>
<p>协方差矩阵对角化：<br>$$<br>PCP^T = \Lambda =<br>\begin{pmatrix}<br>\lambda_1 \\<br>&amp; \lambda_2 \\<br>&amp; &amp; \ddots \\<br>&amp; &amp; &amp; \lambda_n<br>\end{pmatrix}<br>$$</p>
<blockquote>
<p>结论：一个n行n列的实对称矩阵一定可以找到n个单位正交特征向量<br>$$<br>E = \begin{pmatrix} e_1 &amp; e_2 &amp; \cdots &amp; e_n\end{pmatrix}<br>$$<br>实对称矩阵可以进行对角化：<br>$$<br>ECE^T = \Lambda =<br>\begin{pmatrix}<br>\lambda_1 \\<br>&amp; \lambda_2 \\<br>&amp; &amp; \ddots \\<br>&amp; &amp; &amp; \lambda_n<br>\end{pmatrix}<br>$$</p>
</blockquote>
<p>将特征值从大到小排列，用前K行组成的矩阵乘原始数据矩阵X，就得到降维后的数据矩阵Y。</p>
<h2 id="4-示例"><a href="#4-示例" class="headerlink" title="4 示例"></a>4 示例</h2><p>数据（共5个数据，每个数据2个特征点）<br>$$<br>\begin{pmatrix}<br>-1 &amp; -1 &amp; 0 &amp; 2 &amp; 0 \\<br>-2 &amp; 0 &amp; 0 &amp; 1 &amp; 1<br>\end{pmatrix}<br>$$<br>协方差矩阵<br>$$<br>C = \frac{1}{5}<br>\begin{pmatrix}<br>-1 &amp; -1 &amp; 0 &amp; 2 &amp; 0 \\<br>-2 &amp; 0 &amp; 0 &amp; 1 &amp; 1<br>\end{pmatrix}<br>\begin{pmatrix}<br>-1 &amp; -2 \\<br>-1 &amp; 0 \\<br>0 &amp; 0 \\<br>2 &amp; 1 \\<br>0 &amp; 1<br>\end{pmatrix}<br>=<br>\begin{pmatrix}<br>\frac{6}{5} &amp; \frac{4}{5} \\<br>\frac{4}{5} &amp; \frac{6}{5}<br>\end{pmatrix}<br>$$<br>特征值<br>$$<br>\lambda_1 = 2, \lambda_2 = \frac{2}{5}<br>$$<br>特征向量<br>$$<br>c_1<br>\begin{pmatrix}<br>1 \\<br>1<br>\end{pmatrix} ,<br>c_2<br>\begin{pmatrix}<br>-1 \\<br>1<br>\end{pmatrix}<br>$$</p>
<blockquote>
<p>我们求特征值与特征向量的时候，就是为了求矩阵A能使哪些向量（特征向量）只发生伸缩变换，而变换的程度可以用特征值λ表示。</p>
</blockquote>
<p>对角化，我们要降成1维，选择（选择前1大）最大特征值对应的特征向量$c_1$这个<br>$$<br>PCP^T =<br>\begin{pmatrix}<br>\frac{1}{\sqrt 2} &amp; \frac{1}{\sqrt 2} \\<br>-\frac{1}{\sqrt 2} &amp; \frac{1}{\sqrt 2}<br>\end{pmatrix}<br>\begin{pmatrix}<br>\frac{6}{5} &amp; \frac{4}{5} \\<br>\frac{4}{5} &amp; \frac{6}{5}<br>\end{pmatrix}<br>\begin{pmatrix}<br>\frac{1}{\sqrt 2} &amp; -\frac{1}{\sqrt 2} \\<br>\frac{1}{\sqrt 2} &amp; \frac{1}{\sqrt 2}<br>\end{pmatrix}<br>=<br>\begin{pmatrix}<br>2 &amp; 0 \\<br>0 &amp; \frac{2}{5}<br>\end{pmatrix}<br>$$<br>降维<br>$$<br>Y =<br>\begin{pmatrix}<br>\frac{1}{\sqrt 2} &amp; \frac{1}{\sqrt 2}<br>\end{pmatrix}<br>\begin{pmatrix}<br>-1 &amp; -1 &amp; 0 &amp; 2 &amp; 0 \\<br>-2 &amp; 0 &amp; 0 &amp; 1 &amp; 1<br>\end{pmatrix}<br>=<br>\begin{pmatrix}<br>-\frac{3}{\sqrt 2} &amp; -\frac{1}{\sqrt 2} &amp; 0 &amp; \frac{3}{\sqrt 2} &amp; -\frac{1}{\sqrt 2}<br>\end{pmatrix}<br>$$</p>
<blockquote>
<p>PCA降维可参考：<a href="https://zhuanlan.zhihu.com/p/37777074" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/37777074</a></p>
<p>机器学习实战参考：<a href="https://blog.csdn.net/weixin_42600072/category_8751294.html" target="_blank" rel="noopener">https://blog.csdn.net/weixin_42600072/category_8751294.html</a></p>
</blockquote>

            </div>
            <hr />

            
            <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.88rem;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-large waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fa fa-close"></i></a>
            <h4 class="reward-title">写作不易，客官能否打赏一杯奶茶？</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>
            

            <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">

<div id="article-share">
    
    <div class="social-share" data-disabled="qzone" data-wechat-qrcode-helper="<p>微信里点“发现”->“扫一扫”二维码便可查看分享。</p>"></div>
    
</div>

<!-- <script src="/libs/share/js/social-share.min.js"></script> -->
<script src="https://lib.baomitu.com/social-share.js/latest/js/social-share.min.js"></script>


            

    <div class="reprint" id="reprint-statement">
        <p class="reprint-tip">
            <i class="fa fa-exclamation-triangle"></i>&nbsp;&nbsp;
            <span>转载规则</span>
        </p>
        
            <div class="center-align">
                <a rel="license" href="https://creativecommons.org/licenses/by/4.0/deed.zh">
                    <img alt=""
                         style="border-width:0"
                         src="https://i.creativecommons.org/l/by/4.0/88x31.png"/>
                </a>
            </div>
            <br/>
            <span xmlns:dct="http://purl.org/dc/terms/" href="http://purl.org/dc/dcmitype/Text"
                  property="dct:title" rel="dct:type">
                    《机器学习常见算法总结》
                </span> 由
            <a xmlns:cc="http://creativecommons.org/ns#" href="/p/808139430.html" property="cc:attributionName"
               rel="cc:attributionURL">
                行码棋
            </a> 采用
            <a rel="license" href="https://creativecommons.org/licenses/by/4.0/deed.zh">
                知识共享署名 4.0 国际许可协议
            </a>进行许可。
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>


        </div>
    </div>

    
    <link rel="stylesheet" href="https://lib.baomitu.com/gitalk/latest/gitalk.css">
<link rel="stylesheet" href="/css/my-gitalk.css">

<div class="card gitalk-card" data-aos="fade-up">
    <div id="gitalk-container" class="card-content"></div>
</div>


<script src="https://lib.baomitu.com/gitalk/latest/gitalk.min.js"></script>
<script>
    let gitalk = new Gitalk({
        clientID: '132746b84c5638134a72',
        clientSecret: '9026078c86f550ac2f804f817046f2f02aa1bf46',
        repo: 'anda522.github.io',
        owner: 'anda522',
        admin: "anda522",
        id: 'p/808139430.html',  // 使用页面路径生成gitalk id
        
        distractionFreeMode: false  // Facebook-like distraction free mode
    });

    gitalk.render('gitalk-container');
</script>
    

    

    

    

    
    <style>
    .valine-card {
        margin: 1.5rem auto;
    }

    .valine-card .card-content {
        padding: 20px 20px 5px 20px;
    }

    #vcomments input[type=text],
    #vcomments input[type=email],
    #vcomments input[type=url],
    #vcomments textarea {
        box-sizing: border-box;
    }

    #vcomments p {
        margin: 2px 2px 10px;
        font-size: 1.05rem;
        line-height: 1.78rem;
    }

    #vcomments blockquote p {
        text-indent: 0.2rem;
    }

    #vcomments a {
        padding: 0 2px;
        color: #42b983;
        font-weight: 500;
        text-decoration: underline;
    }

    #vcomments img {
        max-width: 100%;
        height: auto;
        cursor: pointer;
    }

    #vcomments ol li {
        list-style-type: decimal;
    }

    #vcomments ol,
    ul {
        display: block;
        padding-left: 2em;
        word-spacing: 0.05rem;
    }

    #vcomments ul li,
    ol li {
        display: list-item;
        line-height: 1.8rem;
        font-size: 1rem;
    }

    #vcomments ul li {
        list-style-type: disc;
    }

    #vcomments ul ul li {
        list-style-type: circle;
    }

    #vcomments table, th, td {
        padding: 12px 13px;
        border: 1px solid #dfe2e5;
    }

    #vcomments table, th, td {
        border: 0;
    }

    table tr:nth-child(2n), thead {
        background-color: #fafafa;
    }

    #vcomments table th {
        background-color: #f2f2f2;
        min-width: 80px;
    }

    #vcomments table td {
        min-width: 80px;
    }

    #vcomments h1 {
        font-size: 1.85rem;
        font-weight: bold;
        line-height: 2.2rem;
    }

    #vcomments h2 {
        font-size: 1.65rem;
        font-weight: bold;
        line-height: 1.9rem;
    }

    #vcomments h3 {
        font-size: 1.45rem;
        font-weight: bold;
        line-height: 1.7rem;
    }

    #vcomments h4 {
        font-size: 1.25rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    #vcomments h5 {
        font-size: 1.1rem;
        font-weight: bold;
        line-height: 1.4rem;
    }

    #vcomments h6 {
        font-size: 1rem;
        line-height: 1.3rem;
    }

    #vcomments p {
        font-size: 1rem;
        line-height: 1.5rem;
    }

    #vcomments hr {
        margin: 12px 0;
        border: 0;
        border-top: 1px solid #ccc;
    }

    #vcomments blockquote {
        margin: 15px 0;
        border-left: 5px solid #42b983;
        padding: 1rem 0.8rem 0.3rem 0.8rem;
        color: #666;
        background-color: rgba(66, 185, 131, .1);
    }

    #vcomments pre {
        font-family: monospace, monospace;
        padding: 1.2em;
        margin: .5em 0;
        background: #272822;
        overflow: auto;
        border-radius: 0.3em;
        tab-size: 4;
    }

    #vcomments code {
        font-family: monospace, monospace;
        padding: 1px 3px;
        font-size: 0.92rem;
        color: #e96900;
        background-color: #f8f8f8;
        border-radius: 2px;
    }

    #vcomments pre code {
        font-family: monospace, monospace;
        padding: 0;
        color: #e8eaf6;
        background-color: #272822;
    }

    #vcomments pre[class*="language-"] {
        padding: 1.2em;
        margin: .5em 0;
    }

    #vcomments code[class*="language-"],
    pre[class*="language-"] {
        color: #e8eaf6;
    }

    #vcomments [type="checkbox"]:not(:checked), [type="checkbox"]:checked {
        position: inherit;
        margin-left: -1.3rem;
        margin-right: 0.4rem;
        margin-top: -1px;
        vertical-align: middle;
        left: unset;
        visibility: visible;
    }

    #vcomments b,
    strong {
        font-weight: bold;
    }

    #vcomments dfn {
        font-style: italic;
    }

    #vcomments small {
        font-size: 85%;
    }

    #vcomments cite {
        font-style: normal;
    }

    #vcomments mark {
        background-color: #fcf8e3;
        padding: .2em;
    }

    #vcomments table, th, td {
        padding: 12px 13px;
        border: 1px solid #dfe2e5;
    }

    table tr:nth-child(2n), thead {
        background-color: #fafafa;
    }

    #vcomments table th {
        background-color: #f2f2f2;
        min-width: 80px;
    }

    #vcomments table td {
        min-width: 80px;
    }

    #vcomments [type="checkbox"]:not(:checked), [type="checkbox"]:checked {
        position: inherit;
        margin-left: -1.3rem;
        margin-right: 0.4rem;
        margin-top: -1px;
        vertical-align: middle;
        left: unset;
        visibility: visible;
    }
</style>

<div class="card valine-card" data-aos="fade-up">
    <div id="vcomments" class="card-content"></div>
</div>

<!-- <script src="/libs/valine/av-min.js"></script> -->
<!-- 需要必填某些选项，所以不能换源 -->
<script src="/libs/valine/Valine.min.js"></script>
<!-- <script src="//code.bdstatic.com/npm/leancloud-storage@4.12.0/dist/av-min.js"></script> -->
<!-- <script src="//unpkg.com/valine@latest/dist/Valine.min.js"></script> -->

<script>
    new Valine({
        el: '#vcomments',
        appId: 'IxO06LubS0JP1nbtF4umMRp6-gzGzoHsz',
        appKey: 'OSn1n1ptwfxMcUAw2D0bbLXU',
        notify: 'false' === 'true',
        verify: 'false' === 'true',
        visitor: 'true' === 'true',
        avatar: 'wavatar',
        pageSize: '10',
        lang: 'zh-cn',
        placeholder: '欢迎提问与质疑，你可以在这里评论啦！',
        serverURLs: '',
        requiredFields: ['mail']
    });
</script>

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fa fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/p/1646942053.html">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/27.jpg" class="responsive-img" alt="2022年度总结">
                        
                        <span class="card-title">2022年度总结</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
希望2023健康，发论文，比赛拿牌，成功上岸。

今天是2023年1月1日，2022有许多不顺心的事，也有一些值得记忆的事，希望通过下面的片段来回顾这年不易的时光。

能说的尽量说，不能说的你我心领神会。我发现时间让我越来越不想说什么东西
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="fa fa-clock-o fa-fw icon-date"></i>2023-01-01
                        </span>
                        <span class="publish-author">
                            
                            <i class="fa fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/哲思/" class="post-category" target="_blank">
                                    哲思
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/阶段性总结/" target="_blank">
                        <span class="chip bg-color">阶段性总结</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fa fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/p/1888017128.html">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/8.jpg" class="responsive-img" alt="Pytorch入门知识总结">
                        
                        <span class="card-title">Pytorch入门知识总结</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Pytorch深度学习入门知识总结GPU相关检查GPU是否工作
import torch
torch.cuda.is_available()
Dataset可以继承Dataset来制作自己的数据类
from torch.utils.data
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="fa fa-clock-o fa-fw icon-date"></i>2022-12-14
                            </span>
                        <span class="publish-author">
                            
                            <i class="fa fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/人工智能/" class="post-category" target="_blank">
                                    人工智能
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Pytorch/" target="_blank">
                        <span class="chip bg-color">Pytorch</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>
</div>


<script>
    $('#articleContent').on('copy', function (e) {
        // IE8 or earlier browser is 'undefined'
        if (typeof window.getSelection === 'undefined') return;

        var selection = window.getSelection();
        // if the selection is short let's not annoy our users.
        if (('' + selection).length < Number.parseInt('120')) {
            return;
        }

        // create a div outside of the visible area and fill it with the selected text.
        var bodyElement = document.getElementsByTagName('body')[0];
        var newdiv = document.createElement('div');
        newdiv.style.position = 'absolute';
        newdiv.style.left = '-99999px';
        bodyElement.appendChild(newdiv);
        newdiv.appendChild(selection.getRangeAt(0).cloneContents());

        // we need a <pre> tag workaround.
        // otherwise the text inside "pre" loses all the line breaks!
        if (selection.getRangeAt(0).commonAncestorContainer.nodeName === 'PRE') {
            newdiv.innerHTML = "<pre>" + newdiv.innerHTML + "</pre>";
        }

        var url = document.location.href;
        newdiv.innerHTML += '<br />'
            + '来源: 行码棋<br />'
            + '作者: 行码棋<br />'
            + '链接: <a href="' + url + '">' + url + '</a><br />'
            + '本文章著作权归作者所有，任何形式的转载都请注明出处。';

        selection.selectAllChildren(newdiv);
        window.setTimeout(function () { bodyElement.removeChild(newdiv); }, 200);
    });
</script>

    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget">
            <div class="toc-title"><i class="fa fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fa fa-list"></i>
    </a>
</div>


<script src="https://lib.baomitu.com/tocbot/latest/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            // headingsOffset: -205,
            headingSelector: 'h1, h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h1, h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).slideUp(500);
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).slideDown(500);
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




<script src="https://lib.baomitu.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$'], ['\(', '\)']]}
    });
</script>

<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>
<!-- 代码语言 -->
<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>
<!-- 代码块复制 -->
<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>
<script type="text/javascript" src="/libs/codeBlock/clipboard.min.js"></script>
<!-- 代码块收缩 -->
<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script> 
<!-- 代码块折行 -->
<style type="text/css">code[class*="language-"], pre[class*="language-"] { white-space: pre !important; }</style>


    <footer class="page-footer bg-color">
    <div class="container row center-align">
        <div class="col s12 m8 l8 copy-right">
            &copy; 2020-2023 行码棋 版权所有

            
            &nbsp;<i class="fa fa-area-chart"></i>&nbsp;站点总字数:&nbsp;
            <span class="white-color">91.1k</span>
            

            <br>
            <span id="sitetime"></span>
            <br>
            <!-- 备案号添加 -->
            <img src="/medias/img/beian.png">
            <a href="http://beian.miit.gov.cn/" style="color:#f72b07" target="_blank">豫ICP备2021035313号-2</a>

            
            
            <br>

            
            <span id="busuanzi_container_site_pv" style='display:none'>
                <i class="fa fa-heart-o"></i>
                本站总访问量 <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
            <span id="busuanzi_container_site_uv" style='display:none'>
                人次,&nbsp;访客数 <span id="busuanzi_value_site_uv" class="white-color"></span> 人.
            </span>
            
            
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/anda522" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fa fa-github"></i>
    </a>



    <a href="mailto:wyq522208@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fa fa-envelope-open"></i>
    </a>





    <a href="http://wpa.qq.com/msgrd?v=3&uin=2579272746&site=qq&menu=yes" class="tooltipped" target="_blank" data-tooltip="访问我的知乎" data-position="top" data-delay="50">
        <i class="fa fa-qq"></i>
    </a>





    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fa fa-rss"></i>
    </a>
</div>
    </div>
</footer>


<div class="progress-bar"></div>

<!-- 不蒜子计数初始值纠正 -->
<script>
    $(document).ready(function () {

        var int = setInterval(fixCount, 50);
        var pvcountOffset = 0;
        var uvcountOffset = 0;

        function fixCount() {
            if (document.getElementById("busuanzi_container_site_pv").style.display != "none") {
                $("#busuanzi_value_site_pv").html(parseInt($("#busuanzi_value_site_pv").html()) + pvcountOffset);
                clearInterval(int);
            }
            if ($("#busuanzi_container_site_pv").css("display") != "none") {
                $("#busuanzi_value_site_uv").html(parseInt($("#busuanzi_value_site_uv").html()) + uvcountOffset); // 加上初始数据 
                clearInterval(int);
            }
        }
    });
</script>

<script language=javascript>
    function siteTime() {
        window.setTimeout("siteTime()", 1000);
        var seconds = 1000;
        var minutes = seconds * 60;
        var hours = minutes * 60;
        var days = hours * 24;
        var years = days * 365;
        var today = new Date();
        var todayYear = today.getFullYear();
        var todayMonth = today.getMonth() + 1;
        var todayDate = today.getDate();
        var todayHour = today.getHours();
        var todayMinute = today.getMinutes();
        var todaySecond = today.getSeconds();
        /* Date.UTC() -- 返回date对象距世界标准时间(UTC)1970年1月1日午夜之间的毫秒数(时间戳)
        year - 作为date对象的年份，为4位年份值
        month - 0-11之间的整数，做为date对象的月份
        day - 1-31之间的整数，做为date对象的天数
        hours - 0(午夜24点)-23之间的整数，做为date对象的小时数
        minutes - 0-59之间的整数，做为date对象的分钟数
        seconds - 0-59之间的整数，做为date对象的秒数
        microseconds - 0-999之间的整数，做为date对象的毫秒数 */
        var t1 = Date.UTC(2022, 06, 23, 00, 00, 00); //北京时间2018-2-13 00:00:00
        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
        var diff = t2 - t1;
        var diffYears = Math.floor(diff / years);
        var diffDays = Math.floor((diff / days) - diffYears * 365);
        var diffHours = Math.floor((diff - (diffYears * 365 + diffDays) * days) / hours);
        var diffMinutes = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours) / minutes);
        var diffSeconds = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours - diffMinutes * minutes) / seconds);
        document.getElementById("sitetime").innerHTML = "本站已运行 " + diffYears + " 年 " + diffDays + " 天 " + diffHours + " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
    }
    siteTime();
</script>



    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fa fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="/js/search.js"></script>
<script type="text/javascript">
$(function () {
    searchFunc("/" + "search.xml", 'searchInput', 'searchResult');
});
</script>
    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fa fa-angle-up"></i>
    </a>
</div>


    <script src="https://lib.baomitu.com/materialize/1.0.0/js/materialize.min.js"></script>
    <script src="https://lib.baomitu.com/masonry/4.0.0/masonry.pkgd.min.js"></script>
    <script src="https://lib.baomitu.com/aos/2.3.4/aos.js"></script>
    <script src="https://lib.baomitu.com/scrollprogress/3.0.2/scrollProgress.min.js"></script>
    <script src="https://lib.baomitu.com/lightgallery/1.6.11/js/lightgallery-all.min.js"></script>

    <script src="/js/matery.js"></script>
    <script src="/js/click_show_text.js"></script>
    
    <script type="text/javascript"> 
        var OriginTitile = document.title, st;
        document.addEventListener("visibilitychange", function () {
            document.hidden ? (document.title = "Σ(っ °Д °;)っ喔哟，崩溃啦！", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) 
        })
    </script>
    
    <!-- 动态线条背景 -->
    <!-- <script type="text/javascript" color="56,152,252" opacity="0.9" zindex="-2" count="200" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js">
    </script>
    <canvas id="c_n4" width="602" height="852" style="position: fixed; top: 0px; left: 0px; z-index: -2; opacity: 0.9;"></canvas> -->
    
    
    <!-- Global site tag (gtag.js) - Google Analytics -->

<script async src="https://www.googletagmanager.com/gtag/js?id=G-JPXWHNDBQ5"></script>
<script>
    window.dataLayer = window.dataLayer || [];
    function gtag() {
        dataLayer.push(arguments);
    }

    gtag('js', new Date());
    gtag('config', 'G-JPXWHNDBQ5');
</script>



    

    <!-- 不蒜子统计修改网页请求头 -->
    
    <script async src="https://lib.baomitu.com/busuanzi/latest/bsz.pure.mini.js"></script>
    <meta name="referrer" content="no-referrer-when-downgrade">
    
    
    
    

</body>

</html>